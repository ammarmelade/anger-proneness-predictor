{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["6ZiHKXJ0JQ2y","Ef8zkNYmaRjh","NyPOPTmDOePz"],"authorship_tag":"ABX9TyMEueP+2vt+CNR0CjqqlvCx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Preliminaries"],"metadata":{"id":"6ZiHKXJ0JQ2y"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"],"metadata":{"id":"irMRi0gI9vH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687438105057,"user_tz":-420,"elapsed":29714,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"47ec600e-5643-4848-9a38-1a12fadd43ef"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wF_EZuxx8-UB","executionInfo":{"status":"ok","timestamp":1687438107784,"user_tz":-420,"elapsed":2737,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"412f1f67-e222-4aef-bfd3-5a4e7bcd8f1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'saint'...\n","remote: Enumerating objects: 664, done.\u001b[K\n","remote: Total 664 (delta 0), reused 0 (delta 0), pack-reused 664\u001b[K\n","Receiving objects: 100% (664/664), 17.00 MiB | 12.72 MiB/s, done.\n","Resolving deltas: 100% (364/364), done.\n"]}],"source":["!git clone https://github.com/ogunlao/saint.git"]},{"cell_type":"code","source":["!pip install pytorch-lightning==1.3.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZ4VpFXm7GDp","executionInfo":{"status":"ok","timestamp":1687438132789,"user_tz":-420,"elapsed":25009,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"4f1b804a-c862-4f9a-8268-f6f621abe655"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning==1.3.2\n","  Downloading pytorch_lightning-1.3.2-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.7/805.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (1.22.4)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (2.0.1+cu118)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (0.18.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (4.65.0)\n","Collecting PyYAML<=5.4.1,>=5.1 (from pytorch-lightning==1.3.2)\n","  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (2023.4.0)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (2.12.2)\n","Collecting torchmetrics>=0.2.0 (from pytorch-lightning==1.3.2)\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyDeprecate==0.3.0 (from pytorch-lightning==1.3.2)\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (2.27.1)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.54.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch-lightning==1.3.2) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch-lightning==1.3.2) (16.0.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->pytorch-lightning==1.3.2) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (3.2.2)\n","Building wheels for collected packages: PyYAML\n","  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=07af87a1d1b94d24d54fa7c3a1e1ffc17e7f99550a8e5a3a4b10b71010c40c22\n","  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n","Successfully built PyYAML\n","Installing collected packages: PyYAML, pyDeprecate, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","Successfully installed PyYAML-5.4.1 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 pyDeprecate-0.3.0 pytorch-lightning-1.3.2 torchmetrics-0.11.4 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["# !pip3 install -r \"/content/saint/requirements.txt\""],"metadata":{"id":"0ECBnzW59KNu","executionInfo":{"status":"ok","timestamp":1687438132790,"user_tz":-420,"elapsed":8,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install scikit-learn==0.24.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czKgW7eW7lTi","executionInfo":{"status":"ok","timestamp":1687438583350,"user_tz":-420,"elapsed":450567,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"600113af-1c41-404d-b726-f4d29e541181"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-learn==0.24.2\n","  Downloading scikit-learn-0.24.2.tar.gz (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.22.4)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.10.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (3.1.0)\n","Building wheels for collected packages: scikit-learn\n","  Building wheel for scikit-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-learn: filename=scikit_learn-0.24.2-cp310-cp310-linux_x86_64.whl size=24897260 sha256=a2ab8c8a2cbd4c81671516578245d96e9e2d76dbc0732b2d3096807d0cd0f9fa\n","  Stored in directory: /root/.cache/pip/wheels/13/a4/68/4e78865652fa14db4a162b491e5138565f97646f9e1f2ab8cc\n","Successfully built scikit-learn\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","imbalanced-learn 0.10.1 requires scikit-learn>=1.0.2, but you have scikit-learn 0.24.2 which is incompatible.\n","yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed scikit-learn-0.24.2\n"]}]},{"cell_type":"code","source":["!pip install scipy==1.5.4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdZC8Xhx7rEc","executionInfo":{"status":"ok","timestamp":1687438731574,"user_tz":-420,"elapsed":148238,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"881c91f7-2233-4083-dd38-f9f3d773eb1b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scipy==1.5.4\n","  Downloading scipy-1.5.4.tar.gz (25.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"]}]},{"cell_type":"code","source":["!pip install tensorboard==2.4.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QzrvzYGU7q_C","executionInfo":{"status":"ok","timestamp":1687438747755,"user_tz":-420,"elapsed":16186,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"3533ccd6-8c2e-43d1-bb5b-b972401c7492"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard==2.4.1\n","  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.54.0)\n","Collecting google-auth<2,>=1.6.3 (from tensorboard==2.4.1)\n","  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.4.1)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (3.4.3)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.22.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (2.27.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (67.7.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (0.40.0)\n","Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard==2.4.1)\n","  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard==2.4.1) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.4.1) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1) (3.2.2)\n","Installing collected packages: cachetools, google-auth, google-auth-oauthlib, tensorboard\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 5.3.0\n","    Uninstalling cachetools-5.3.0:\n","      Successfully uninstalled cachetools-5.3.0\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 2.17.3\n","    Uninstalling google-auth-2.17.3:\n","      Successfully uninstalled google-auth-2.17.3\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.35.0 which is incompatible.\n","google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 1.35.0 which is incompatible.\n","tensorflow 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cachetools-4.2.4 google-auth-1.35.0 google-auth-oauthlib-0.4.6 tensorboard-2.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install tensorboard-plugin-wit==1.8.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNz-mi0s7q0l","executionInfo":{"status":"ok","timestamp":1687438754072,"user_tz":-420,"elapsed":6326,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"472ac885-3e39-4b41-d573-311e55b1624e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard-plugin-wit==1.8.0\n","  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.2/781.2 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard-plugin-wit\n","  Attempting uninstall: tensorboard-plugin-wit\n","    Found existing installation: tensorboard-plugin-wit 1.8.1\n","    Uninstalling tensorboard-plugin-wit-1.8.1:\n","      Successfully uninstalled tensorboard-plugin-wit-1.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorboard-plugin-wit-1.8.0\n"]}]},{"cell_type":"code","source":["!pip install torch==1.8.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sk55Z5-d75xp","executionInfo":{"status":"ok","timestamp":1687438756158,"user_tz":-420,"elapsed":2093,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"e666b635-e146-43ae-9325-57f2900d8180"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.1\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install torchmetrics==0.3.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"832RK6OB78_Y","executionInfo":{"status":"ok","timestamp":1687438762433,"user_tz":-420,"elapsed":6290,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"9d030acf-1f68-4564-e3f3-cdd9c652f54c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics==0.3.2\n","  Downloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.3.2) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.3.2) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.1->torchmetrics==0.3.2) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.1->torchmetrics==0.3.2) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.1->torchmetrics==0.3.2) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.1->torchmetrics==0.3.2) (1.3.0)\n","Installing collected packages: torchmetrics\n","  Attempting uninstall: torchmetrics\n","    Found existing installation: torchmetrics 0.11.4\n","    Uninstalling torchmetrics-0.11.4:\n","      Successfully uninstalled torchmetrics-0.11.4\n","Successfully installed torchmetrics-0.3.2\n"]}]},{"cell_type":"code","source":["!pip install torchtext==0.6.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cBUbpbK7_ji","executionInfo":{"status":"ok","timestamp":1687438768756,"user_tz":-420,"elapsed":6334,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"6bdb401c-10a9-4a7f-b6a9-c18c847b954b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Collecting sentencepiece (from torchtext==0.6.0)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.2\n","    Uninstalling torchtext-0.15.2:\n","      Successfully uninstalled torchtext-0.15.2\n","Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"]}]},{"cell_type":"code","source":["!pip install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIYK5adF7_et","executionInfo":{"status":"ok","timestamp":1687438772428,"user_tz":-420,"elapsed":3682,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"0513cb68-bedd-4477-fc5a-7dff6f73acc1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install hydra-core"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463},"id":"S6QGqYdU8Frx","executionInfo":{"status":"ok","timestamp":1687438783506,"user_tz":-420,"elapsed":11084,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"582add04-cfed-43f0-e378-5a37a75c03fc"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.1)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (5.4.1)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=7d25ece5055f736b1ab52bc0caa3a2aee795d6310dc44315a5064e2c0e7c4d78\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n","Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install ruamel_yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZpR1cNo8IRD","executionInfo":{"status":"ok","timestamp":1687438791242,"user_tz":-420,"elapsed":7748,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"273d36d4-ac55-4848-80a0-c814d6c05320"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ruamel_yaml\n","  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel_yaml)\n","  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel_yaml\n","Successfully installed ruamel.yaml.clib-0.2.7 ruamel_yaml-0.17.32\n"]}]},{"cell_type":"code","source":["!pip install imbalanced-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UIAgNJWe9Pi","executionInfo":{"status":"ok","timestamp":1687438799589,"user_tz":-420,"elapsed":8353,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"cb9341b7-3229-4646-9061-09e8091d3fbf"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n","Collecting scikit-learn>=1.0.2 (from imbalanced-learn)\n","  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.24.2\n","    Uninstalling scikit-learn-0.24.2:\n","      Successfully uninstalled scikit-learn-0.24.2\n","Successfully installed scikit-learn-1.2.2\n"]}]},{"cell_type":"code","source":["# !pip install torch --upgrade torch\n","# !pip install torch --upgrade pytorch-lightning"],"metadata":{"id":"RMjvVdfYITxk","executionInfo":{"status":"ok","timestamp":1687438799590,"user_tz":-420,"elapsed":36,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# !nvcc --version"],"metadata":{"id":"WEdpJXk_I_lg","executionInfo":{"status":"ok","timestamp":1687438799591,"user_tz":-420,"elapsed":34,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# IMPORTANT : EDIT FILE-FILE INI DULU SEBELUM RUN"],"metadata":{"id":"Ef8zkNYmaRjh"}},{"cell_type":"markdown","source":["Cara editnya : double-click file yg mau di edit di \"Files\" (tab kiri colab) ato klik link-link dibawah, terus ctrl-s buat save.\n","\n","```1. /content/saint/configs/config.yaml, line 21```\n","\n","```\n","optimizer:\n","  # parameter for contrastive loss\n","  temperature: 0.7\n","  proj_head_dim: 128\n","\n","  # parameters for training\n","  beta_1: 0.9\n","  beta_2: 0.99\n","  lr: 0.0001\n","  weight_decay: 0.01\n","  optim: adamw\n","  metric: acc\n","\n","preproc:\n","  data_folder: null\n","  train_split: 0.65\n","  validation_split: 0.15\n","  test_split: 0.20\n","  num_supervised_train_data: null # {all 50 200 500}\n","\n","callback:\n","  monitor: val_loss # {val_loss, val_auroc_epoch}\n","  mode: min # {max, min}\n","  auto_insert_metric_name: false\n","\n","trainer:\n","  max_epochs: 10\n","  gpus: 1\n","  deterministic: true\n","  default_root_dir: null\n","  resume_from_checkpoint: null\n","```\n","\n","```2. /content/saint/configs/data/bank_ssl.yaml, line 10```\n","```\n","data_stats:\n","  no_cat: 1\n","  no_num: 49\n","  cats: [1]\n","```\n","\n","```3. /content/saint/configs/data/bank_sup.yaml, line 10```\n","\n","```\n","data_stats:\n","  no_cat: 1\n","  no_num: 49\n","  cats: [1]\n","```\n","\n","```4. /content/saint/configs/experiment/supervised.yaml```\n","\n","```\n","experiment: supervised\n","task: classification\n","model: saint\n","num_output: 5\n","freeze_encoder: false\n","pretrained_checkpoint: null #checkpoints/lightning_logs/version_7/checkpoints/epoch=0-step=1.ckpt\n","```\n","\n","```5. /content/saint/configs/experiment/self-supervised.yaml```\n","\n","```\n","experiment: self-supervised\n","task: classification\n","model: saint\n","num_output: 5\n","freeze_encoder: false\n","pretrained_checkpoint: null #checkpoints/lightning_logs/version_7/checkpoints/epoch=0-step=1.ckpt\n","```\n","\n","```4. /content/saint/configs/experiment/predict.yaml```\n","\n","```\n","model: saint\n","task: classification\n","pretrained_checkpoint: ?? #nulll\n","num_output: 5\n","\n","pred_sav_path: ?? # path to save prediction e.g \"\"./prediction.csv\"\n","save_prediction: true\n","id_col: index\n","target_col: target\n","```"],"metadata":{"id":"fdYj59RZzVWT"}},{"cell_type":"markdown","source":["\n","# Setting up parameters"],"metadata":{"id":"Q5gQs6SaILhx"}},{"cell_type":"code","source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","\n","from ruamel.yaml import YAML\n","\n","import torch\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VEnYWP1KH_Z","executionInfo":{"status":"ok","timestamp":1687438910314,"user_tz":-420,"elapsed":7700,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"14368cba-35a5-45d3-8c1d-caf5a7c06248"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"code","source":["data_folder = \"/content/saint/data\"\n","\n","os.mkdir(\"/content/saint/data\")"],"metadata":{"id":"b2yZLsEkI1Ex","executionInfo":{"status":"ok","timestamp":1687438910314,"user_tz":-420,"elapsed":11,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["config_path = 'saint/configs/config.yaml'\n","\n","yaml = YAML(typ='safe')\n","with open(config_path) as f:\n","  args = yaml.load(f)\n","\n","print(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3yBXKWlIOjL","executionInfo":{"status":"ok","timestamp":1687438910315,"user_tz":-420,"elapsed":12,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"25e99ed2-9eed-4390-ed28-95e888cafee7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["{'defaults': ['_self_', {'experiment': 'supervised'}, {'data': 'bank_sup'}], 'seed': 1234, 'transformer': {'num_layers': 6, 'num_heads': 8, 'dropout': 0.1, 'dropout_ff': 0.1, 'embed_dim': 32, 'd_ff': 32, 'cls_token_idx': 0}, 'augmentation': {'prob_cutmix': 0.3, 'alpha': 0.2, 'lambda_pt': 10}, 'optimizer': {'temperature': 0.7, 'proj_head_dim': 128, 'beta_1': 0.9, 'beta_2': 0.99, 'lr': 0.0001, 'weight_decay': 0.01, 'optim': 'adamw', 'metric': 'acc'}, 'preproc': {'data_folder': None, 'train_split': 0.65, 'validation_split': 0.15, 'test_split': 0.2, 'num_supervised_train_data': None}, 'callback': {'monitor': 'val_loss', 'mode': 'min', 'auto_insert_metric_name': False}, 'trainer': {'max_epochs': 10, 'gpus': 1, 'deterministic': True, 'default_root_dir': None, 'resume_from_checkpoint': None}, 'dataloader': {'shuffle_val': False, 'train_bs': 32, 'val_bs': 32, 'test_bs': 16, 'num_workers': 2, 'pin_memory': False}, 'metric': '${optimizer.metric}', 'print_config': False}\n"]}]},{"cell_type":"markdown","source":["# Data preprocessing"],"metadata":{"id":"mIFvOAGlIueV"}},{"cell_type":"code","source":["dataset = pd.read_csv(\"/content/drive/MyDrive/SEM4/Research Method/RM Kel 19 Experiment/data-final.csv\", sep='\\t')\n","\n","print(dataset.shape)\n","dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"0NCa-gD39lta","executionInfo":{"status":"ok","timestamp":1687438929213,"user_tz":-420,"elapsed":18904,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"1b875ad4-e413-4d30-8098-719359d5809e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["(1015341, 110)\n"]},{"output_type":"execute_result","data":{"text/plain":["   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n","0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   \n","1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   \n","2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   \n","3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   \n","4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   \n","\n","              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n","0  2016-03-03 02:01:01    768.0   1024.0          9.0       234.0          6   \n","1  2016-03-03 02:01:20   1360.0    768.0         12.0       179.0         11   \n","2  2016-03-03 02:01:56   1366.0    768.0          3.0       186.0          7   \n","3  2016-03-03 02:02:02   1920.0   1200.0        186.0       219.0          7   \n","4  2016-03-03 02:02:57   1366.0    768.0          8.0       315.0         17   \n","\n","   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n","0    1       GB               51.5448                 0.1991  \n","1    1       MY                3.1698                101.706  \n","2    1       GB               54.9119                -1.3833  \n","3    1       GB                 51.75                  -1.25  \n","4    2       KE                   1.0                   38.0  \n","\n","[5 rows x 110 columns]"],"text/html":["\n","  <div id=\"df-9a1b64b5-2427-4967-9381-cc5eeaebc87a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EXT1</th>\n","      <th>EXT2</th>\n","      <th>EXT3</th>\n","      <th>EXT4</th>\n","      <th>EXT5</th>\n","      <th>EXT6</th>\n","      <th>EXT7</th>\n","      <th>EXT8</th>\n","      <th>EXT9</th>\n","      <th>EXT10</th>\n","      <th>...</th>\n","      <th>dateload</th>\n","      <th>screenw</th>\n","      <th>screenh</th>\n","      <th>introelapse</th>\n","      <th>testelapse</th>\n","      <th>endelapse</th>\n","      <th>IPC</th>\n","      <th>country</th>\n","      <th>lat_appx_lots_of_err</th>\n","      <th>long_appx_lots_of_err</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:01:01</td>\n","      <td>768.0</td>\n","      <td>1024.0</td>\n","      <td>9.0</td>\n","      <td>234.0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>GB</td>\n","      <td>51.5448</td>\n","      <td>0.1991</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:01:20</td>\n","      <td>1360.0</td>\n","      <td>768.0</td>\n","      <td>12.0</td>\n","      <td>179.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>MY</td>\n","      <td>3.1698</td>\n","      <td>101.706</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:01:56</td>\n","      <td>1366.0</td>\n","      <td>768.0</td>\n","      <td>3.0</td>\n","      <td>186.0</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>GB</td>\n","      <td>54.9119</td>\n","      <td>-1.3833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:02:02</td>\n","      <td>1920.0</td>\n","      <td>1200.0</td>\n","      <td>186.0</td>\n","      <td>219.0</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>GB</td>\n","      <td>51.75</td>\n","      <td>-1.25</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:02:57</td>\n","      <td>1366.0</td>\n","      <td>768.0</td>\n","      <td>8.0</td>\n","      <td>315.0</td>\n","      <td>17</td>\n","      <td>2</td>\n","      <td>KE</td>\n","      <td>1.0</td>\n","      <td>38.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 110 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a1b64b5-2427-4967-9381-cc5eeaebc87a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9a1b64b5-2427-4967-9381-cc5eeaebc87a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9a1b64b5-2427-4967-9381-cc5eeaebc87a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["dataset = dataset.drop(list(dataset)[50:], axis=1)\n","\n","print(dataset.shape)\n","dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"kKU71FbL-CH1","executionInfo":{"status":"ok","timestamp":1687438929216,"user_tz":-420,"elapsed":27,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"4addb382-3407-40a4-a69d-0db6a1507d26"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["(1015341, 50)\n"]},{"output_type":"execute_result","data":{"text/plain":["   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  OPN1  \\\n","0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   5.0   \n","1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   1.0   \n","2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   5.0   \n","3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   4.0   \n","4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   5.0   \n","\n","   OPN2  OPN3  OPN4  OPN5  OPN6  OPN7  OPN8  OPN9  OPN10  \n","0   1.0   4.0   1.0   4.0   1.0   5.0   3.0   4.0    5.0  \n","1   2.0   4.0   2.0   3.0   1.0   4.0   2.0   5.0    3.0  \n","2   1.0   2.0   1.0   4.0   2.0   5.0   3.0   4.0    4.0  \n","3   2.0   5.0   2.0   3.0   1.0   4.0   4.0   3.0    3.0  \n","4   1.0   5.0   1.0   5.0   1.0   5.0   3.0   5.0    5.0  \n","\n","[5 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-84a94567-c61b-4f24-a29d-9a045f501f36\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EXT1</th>\n","      <th>EXT2</th>\n","      <th>EXT3</th>\n","      <th>EXT4</th>\n","      <th>EXT5</th>\n","      <th>EXT6</th>\n","      <th>EXT7</th>\n","      <th>EXT8</th>\n","      <th>EXT9</th>\n","      <th>EXT10</th>\n","      <th>...</th>\n","      <th>OPN1</th>\n","      <th>OPN2</th>\n","      <th>OPN3</th>\n","      <th>OPN4</th>\n","      <th>OPN5</th>\n","      <th>OPN6</th>\n","      <th>OPN7</th>\n","      <th>OPN8</th>\n","      <th>OPN9</th>\n","      <th>OPN10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 50 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84a94567-c61b-4f24-a29d-9a045f501f36')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-84a94567-c61b-4f24-a29d-9a045f501f36 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-84a94567-c61b-4f24-a29d-9a045f501f36');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["for i in dataset.columns:\n","  dataset = dataset[(dataset[i].notna()) & (dataset[i] != 0)]\n","\n","print(dataset.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z75-zCjK-IiC","executionInfo":{"status":"ok","timestamp":1687438937653,"user_tz":-420,"elapsed":8454,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"638f683c-cbbc-451e-8de4-4c2bfed842e7"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["(874434, 50)\n"]}]},{"cell_type":"code","source":["data = dataset.astype(int)"],"metadata":{"id":"v6-PfEfr9vjd","executionInfo":{"status":"ok","timestamp":1687439321897,"user_tz":-420,"elapsed":518,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["data = data[:100000]"],"metadata":{"id":"rOAEEVuG1oC5","executionInfo":{"status":"ok","timestamp":1687439337749,"user_tz":-420,"elapsed":4,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["x = data.drop(columns=['EST9'])\n","y = data['EST9']"],"metadata":{"id":"f9Arorto-KIy","executionInfo":{"status":"ok","timestamp":1687439340086,"user_tz":-420,"elapsed":7,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["class_counts = data['EST9'].value_counts()\n","data['EST9'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fK-gKGep-GKA","executionInfo":{"status":"ok","timestamp":1687439340633,"user_tz":-420,"elapsed":4,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"11984130-7979-4d5c-d743-0b8b48f30197"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    28445\n","2    22389\n","3    21401\n","5    15258\n","1    12507\n","Name: EST9, dtype: int64"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["plt.bar(class_counts.index, height=class_counts.values, width=0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"eCagsDIkmbFa","executionInfo":{"status":"ok","timestamp":1687439346202,"user_tz":-420,"elapsed":599,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"776a348f-72bc-4f37-dab9-e63197ee1c9c"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BarContainer object of 5 artists>"]},"metadata":{},"execution_count":44},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Random undersampling"],"metadata":{"id":"c2YgOxdnlal2"}},{"cell_type":"code","source":["from imblearn.under_sampling  import RandomUnderSampler\n","\n","undersampler = RandomUnderSampler(random_state=42)\n","\n","x, y = undersampler.fit_resample(x, y)"],"metadata":{"id":"kzQTOKdBfCic","executionInfo":{"status":"ok","timestamp":1687439355805,"user_tz":-420,"elapsed":596,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["y.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5bspKd4hfBs","executionInfo":{"status":"ok","timestamp":1687439358680,"user_tz":-420,"elapsed":5,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"7c3def3a-f454-459a-a7ed-c913060c1107"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    12507\n","2    12507\n","3    12507\n","4    12507\n","5    12507\n","Name: EST9, dtype: int64"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["y = y - 1"],"metadata":{"id":"QN7RPmy9S8X9","executionInfo":{"status":"ok","timestamp":1687439362599,"user_tz":-420,"elapsed":529,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0i1XE2vciWOg","executionInfo":{"status":"ok","timestamp":1687439363342,"user_tz":-420,"elapsed":5,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"708c40f0-cb3e-4a66-c569-fc749dfa21c7"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(62535,)"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["## Splitting dataset"],"metadata":{"id":"tAdrYEA-lXSx"}},{"cell_type":"code","source":["from saint.src.dataset import generate_splits, preprocess"],"metadata":{"id":"XYfjIiOeJe91","executionInfo":{"status":"ok","timestamp":1687439376217,"user_tz":-420,"elapsed":804,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["num_supervised_train_data = 62535//2\n","\n","sup_train_indices, val_indices, test_indices, ssl_train_indices = generate_splits(len(x), num_supervised_train_data, args['preproc']['validation_split'], args['preproc']['test_split'], args['seed'],)"],"metadata":{"id":"sBdu-PJLJjt_","executionInfo":{"status":"ok","timestamp":1687439376218,"user_tz":-420,"elapsed":3,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["x_proc, y_proc, no_num, no_cat, cats  = preprocess(x, y, args['transformer']['cls_token_idx'])"],"metadata":{"id":"1ldx0xi8J9mT","executionInfo":{"status":"ok","timestamp":1687439378270,"user_tz":-420,"elapsed":4,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["print('no of numerical columns: ', no_num)\n","print('no of categorical columns: ', no_cat)\n","\n","print('list of categories in each categorical column: ', cats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99TtxxqOKEMK","executionInfo":{"status":"ok","timestamp":1687439378271,"user_tz":-420,"elapsed":4,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"aa8ef712-cb69-4f63-d8e3-9babe39d99f4"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["no of numerical columns:  49\n","no of categorical columns:  1\n","list of categories in each categorical column:  [1]\n"]}]},{"cell_type":"code","source":["train_df, train_y   = x_proc.iloc[sup_train_indices], y_proc.iloc[sup_train_indices]\n","val_df, val_y       = x_proc.iloc[val_indices], y_proc.iloc[val_indices]\n","test_df, test_y     = x_proc.iloc[test_indices], y_proc.iloc[test_indices]"],"metadata":{"id":"zO_CGazRKIlS","executionInfo":{"status":"ok","timestamp":1687439379895,"user_tz":-420,"elapsed":4,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["train_ssl, train_ssl_y = None, None\n","\n","if num_supervised_train_data != 'all':\n","    train_ssl, train_ssl_y = x_proc.iloc[ssl_train_indices], y_proc.iloc[ssl_train_indices]"],"metadata":{"id":"xdM8JYynKciy","executionInfo":{"status":"ok","timestamp":1687439380956,"user_tz":-420,"elapsed":2,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["train_df.to_csv('/content/saint/data/train.csv' , index=False)\n","train_y.to_csv('/content/saint/data/train_y.csv' , index=False)\n","val_df.to_csv('/content/saint/data/val.csv' , index=False)\n","val_y.to_csv('/content/saint/data/val_y.csv' , index=False)\n","test_df.to_csv('/content/saint/data/test.csv' , index=False)\n","test_y.to_csv('/content/saint/data/test_y.csv' , index=False)\n","\n","if train_ssl is not None:\n","   train_ssl.to_csv('/content/saint/data/train_ssl.csv' , index=False)\n","\n","if train_ssl_y is not None:\n","  train_ssl_y.to_csv('/content/saint/data/train_ssl_y.csv' , index=False)"],"metadata":{"id":"xn-T7swhKpmA","executionInfo":{"status":"ok","timestamp":1687439384680,"user_tz":-420,"elapsed":3197,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["# SAINT training"],"metadata":{"id":"XK3XHgVCGfOm"}},{"cell_type":"code","source":["num_gpus = 1\n","\n","os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"mqJKcN-ZNr7i","executionInfo":{"status":"ok","timestamp":1687439384682,"user_tz":-420,"elapsed":7,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["## Self-supervised learning + supervised learning"],"metadata":{"id":"rZyNJ8mpOm6A"}},{"cell_type":"markdown","source":["### Self-supervised learning"],"metadata":{"id":"D_Cy9HLRMY4C"}},{"cell_type":"code","source":["!python /content/saint/main.py experiment=self-supervised \\\n","  experiment.model=saint \\\n","  data.data_folder=/content/saint/data \\\n","  data=bank_ssl"],"metadata":{"id":"tVpqTt4RLUV7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687440234088,"user_tz":-420,"elapsed":849412,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"dad642c3-5ff5-493d-fa0b-027f1e477cdb"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-22 13:09:47.538933: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-22 13:09:48.853744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/main.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Global seed set to 1234\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name                | Type            | Params\n","--------------------------------------------------------\n","0 | transformer         | Encoder         | 65.0 K\n","1 | embedding           | Embedding       | 3.2 K \n","2 | contrastive_loss_fn | ContrastiveLoss | 409 K \n","3 | denoising_loss_fn   | DenoisingLoss   | 1.6 K \n","--------------------------------------------------------\n","479 K     Trainable params\n","0         Non-trainable params\n","479 K     Total params\n","1.918     Total estimated model params size (MB)\n","Global seed set to 1234\n","Epoch 0:  51% 300/588 [01:02<00:59,  4.81it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  54% 320/588 [01:03<00:53,  5.02it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  58% 340/588 [01:05<00:47,  5.21it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  61% 360/588 [01:06<00:42,  5.38it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  65% 380/588 [01:08<00:37,  5.53it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  68% 400/588 [01:10<00:32,  5.70it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  71% 420/588 [01:11<00:28,  5.88it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  75% 440/588 [01:13<00:24,  6.02it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  78% 460/588 [01:14<00:20,  6.15it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  82% 480/588 [01:16<00:17,  6.31it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  85% 500/588 [01:17<00:13,  6.47it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  88% 520/588 [01:18<00:10,  6.62it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  92% 540/588 [01:19<00:07,  6.75it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  95% 560/588 [01:21<00:04,  6.87it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0:  99% 580/588 [01:23<00:01,  6.97it/s, loss=592, v_num=0, val_loss_epoch=735.0, train_loss_step=634.0]\n","Epoch 0: 100% 588/588 [01:24<00:00,  6.95it/s, loss=582, v_num=0, val_loss_epoch=601.0, train_loss_step=322.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  51% 300/588 [01:03<01:00,  4.73it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  54% 320/588 [01:04<00:54,  4.94it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  58% 340/588 [01:06<00:48,  5.15it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  61% 360/588 [01:07<00:42,  5.35it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  65% 380/588 [01:08<00:37,  5.54it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  68% 400/588 [01:09<00:32,  5.73it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  71% 420/588 [01:11<00:28,  5.89it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  75% 440/588 [01:12<00:24,  6.03it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  78% 460/588 [01:14<00:20,  6.15it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  82% 480/588 [01:16<00:17,  6.30it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  85% 500/588 [01:17<00:13,  6.45it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  88% 520/588 [01:18<00:10,  6.60it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  92% 540/588 [01:20<00:07,  6.75it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  95% 560/588 [01:21<00:04,  6.89it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1:  99% 580/588 [01:22<00:01,  7.02it/s, loss=600, v_num=0, val_loss_epoch=601.0, train_loss_step=592.0, train_loss_epoch=603.0, val_loss_step=500.0]\n","Epoch 1: 100% 588/588 [01:23<00:00,  7.04it/s, loss=585, v_num=0, val_loss_epoch=601.0, train_loss_step=429.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  51% 300/588 [01:03<01:00,  4.73it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  54% 320/588 [01:05<00:54,  4.90it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  58% 340/588 [01:07<00:48,  5.06it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  61% 360/588 [01:08<00:43,  5.26it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  65% 380/588 [01:09<00:38,  5.45it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  68% 400/588 [01:10<00:33,  5.64it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  71% 420/588 [01:12<00:28,  5.81it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  75% 440/588 [01:13<00:24,  5.99it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  78% 460/588 [01:14<00:20,  6.15it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  82% 480/588 [01:15<00:17,  6.32it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  85% 500/588 [01:17<00:13,  6.47it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  88% 520/588 [01:18<00:10,  6.60it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  92% 540/588 [01:20<00:07,  6.72it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  95% 560/588 [01:22<00:04,  6.81it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2:  99% 580/588 [01:23<00:01,  6.95it/s, loss=595, v_num=0, val_loss_epoch=601.0, train_loss_step=544.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 2: 100% 588/588 [01:24<00:00,  6.96it/s, loss=599, v_num=0, val_loss_epoch=601.0, train_loss_step=538.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  51% 300/588 [01:03<01:00,  4.76it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  54% 320/588 [01:04<00:53,  4.96it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  58% 340/588 [01:05<00:47,  5.17it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  61% 360/588 [01:07<00:42,  5.37it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  65% 380/588 [01:08<00:37,  5.55it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  68% 400/588 [01:09<00:32,  5.71it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  71% 420/588 [01:11<00:28,  5.86it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  75% 440/588 [01:13<00:24,  6.00it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  78% 460/588 [01:14<00:20,  6.16it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  82% 480/588 [01:15<00:17,  6.33it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  85% 500/588 [01:17<00:13,  6.48it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  88% 520/588 [01:18<00:10,  6.63it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  92% 540/588 [01:19<00:07,  6.78it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  95% 560/588 [01:20<00:04,  6.92it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3:  99% 580/588 [01:22<00:01,  7.06it/s, loss=606, v_num=0, val_loss_epoch=601.0, train_loss_step=549.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 3: 100% 588/588 [01:23<00:00,  7.07it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=463.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  51% 300/588 [01:03<01:00,  4.74it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  54% 320/588 [01:05<00:54,  4.91it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  58% 340/588 [01:06<00:48,  5.12it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  61% 360/588 [01:07<00:42,  5.32it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  65% 380/588 [01:08<00:37,  5.51it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  68% 400/588 [01:10<00:32,  5.70it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  71% 420/588 [01:11<00:28,  5.88it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  75% 440/588 [01:12<00:24,  6.05it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  78% 460/588 [01:13<00:20,  6.22it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  82% 480/588 [01:15<00:16,  6.37it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  85% 500/588 [01:16<00:13,  6.50it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  88% 520/588 [01:18<00:10,  6.62it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  92% 540/588 [01:20<00:07,  6.72it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  95% 560/588 [01:21<00:04,  6.87it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4:  99% 580/588 [01:22<00:01,  7.01it/s, loss=597, v_num=0, val_loss_epoch=601.0, train_loss_step=569.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 4: 100% 588/588 [01:23<00:00,  7.02it/s, loss=599, v_num=0, val_loss_epoch=601.0, train_loss_step=563.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  51% 300/588 [01:02<01:00,  4.76it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 5:  54% 320/588 [01:04<00:53,  4.97it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  58% 340/588 [01:05<00:47,  5.19it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  61% 360/588 [01:06<00:42,  5.38it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  65% 380/588 [01:08<00:37,  5.55it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  68% 400/588 [01:10<00:32,  5.70it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  71% 420/588 [01:11<00:28,  5.84it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  75% 440/588 [01:13<00:24,  6.02it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  78% 460/588 [01:14<00:20,  6.18it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  82% 480/588 [01:15<00:17,  6.35it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  85% 500/588 [01:16<00:13,  6.51it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  88% 520/588 [01:18<00:10,  6.66it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  92% 540/588 [01:19<00:07,  6.80it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  95% 560/588 [01:20<00:04,  6.94it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5:  99% 580/588 [01:21<00:01,  7.08it/s, loss=592, v_num=0, val_loss_epoch=601.0, train_loss_step=552.0, train_loss_epoch=600.0, val_loss_step=500.0]\n","Epoch 5: 100% 588/588 [01:23<00:00,  7.07it/s, loss=584, v_num=0, val_loss_epoch=597.0, train_loss_step=359.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  51% 300/588 [01:03<01:00,  4.72it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 6:  54% 320/588 [01:04<00:54,  4.93it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  58% 340/588 [01:06<00:48,  5.14it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  61% 360/588 [01:07<00:42,  5.34it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  65% 380/588 [01:08<00:37,  5.54it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  68% 400/588 [01:09<00:32,  5.73it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  71% 420/588 [01:11<00:28,  5.91it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  75% 440/588 [01:12<00:24,  6.08it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  78% 460/588 [01:13<00:20,  6.24it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  82% 480/588 [01:15<00:16,  6.38it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  85% 500/588 [01:16<00:13,  6.51it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  88% 520/588 [01:18<00:10,  6.61it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  92% 540/588 [01:19<00:07,  6.76it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  95% 560/588 [01:21<00:04,  6.91it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6:  99% 580/588 [01:22<00:01,  7.04it/s, loss=596, v_num=0, val_loss_epoch=597.0, train_loss_step=573.0, train_loss_epoch=599.0, val_loss_step=487.0]\n","Epoch 6: 100% 588/588 [01:23<00:00,  7.06it/s, loss=599, v_num=0, val_loss_epoch=595.0, train_loss_step=485.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  51% 300/588 [01:03<01:00,  4.76it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 7:  54% 320/588 [01:04<00:53,  4.97it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  58% 340/588 [01:05<00:48,  5.16it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  61% 360/588 [01:07<00:42,  5.34it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  65% 380/588 [01:09<00:37,  5.51it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  68% 400/588 [01:10<00:33,  5.65it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  71% 420/588 [01:12<00:28,  5.83it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  75% 440/588 [01:13<00:24,  6.00it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  78% 460/588 [01:14<00:20,  6.17it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  82% 480/588 [01:15<00:17,  6.33it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  85% 500/588 [01:17<00:13,  6.49it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  88% 520/588 [01:18<00:10,  6.64it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  92% 540/588 [01:19<00:07,  6.79it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  95% 560/588 [01:20<00:04,  6.93it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7:  99% 580/588 [01:22<00:01,  7.04it/s, loss=598, v_num=0, val_loss_epoch=595.0, train_loss_step=639.0, train_loss_epoch=597.0, val_loss_step=495.0]\n","Epoch 7: 100% 588/588 [01:23<00:00,  7.03it/s, loss=580, v_num=0, val_loss_epoch=592.0, train_loss_step=405.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  51% 300/588 [01:03<01:00,  4.74it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 8:  54% 320/588 [01:04<00:54,  4.95it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  58% 340/588 [01:05<00:48,  5.16it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  61% 360/588 [01:07<00:42,  5.37it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  65% 380/588 [01:08<00:37,  5.56it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  68% 400/588 [01:09<00:32,  5.75it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  71% 420/588 [01:10<00:28,  5.93it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  75% 440/588 [01:12<00:24,  6.11it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  78% 460/588 [01:13<00:20,  6.25it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  82% 480/588 [01:15<00:16,  6.38it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  85% 500/588 [01:17<00:13,  6.48it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  88% 520/588 [01:18<00:10,  6.64it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  92% 540/588 [01:19<00:07,  6.78it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  95% 560/588 [01:20<00:04,  6.93it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8:  99% 580/588 [01:22<00:01,  7.06it/s, loss=576, v_num=0, val_loss_epoch=592.0, train_loss_step=560.0, train_loss_epoch=595.0, val_loss_step=483.0]\n","Epoch 8: 100% 588/588 [01:23<00:00,  7.08it/s, loss=575, v_num=0, val_loss_epoch=590.0, train_loss_step=541.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  51% 300/588 [01:02<00:59,  4.80it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 9:  54% 320/588 [01:03<00:53,  5.01it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  58% 340/588 [01:05<00:47,  5.21it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  61% 360/588 [01:06<00:42,  5.38it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  65% 380/588 [01:08<00:37,  5.53it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  68% 400/588 [01:10<00:32,  5.70it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  71% 420/588 [01:11<00:28,  5.88it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  75% 440/588 [01:12<00:24,  6.05it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  78% 460/588 [01:13<00:20,  6.22it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  82% 480/588 [01:15<00:16,  6.39it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  85% 500/588 [01:16<00:13,  6.55it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  88% 520/588 [01:17<00:10,  6.70it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  92% 540/588 [01:18<00:07,  6.85it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  95% 560/588 [01:20<00:04,  6.97it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9:  99% 580/588 [01:21<00:01,  7.08it/s, loss=603, v_num=0, val_loss_epoch=590.0, train_loss_step=652.0, train_loss_epoch=593.0, val_loss_step=510.0]\n","Epoch 9: 100% 588/588 [01:23<00:00,  7.07it/s, loss=586, v_num=0, val_loss_epoch=587.0, train_loss_step=414.0, train_loss_epoch=591.0, val_loss_step=473.0]\n","Epoch 9: 100% 588/588 [01:23<00:00,  7.03it/s, loss=586, v_num=0, val_loss_epoch=587.0, train_loss_step=414.0, train_loss_epoch=591.0, val_loss_step=473.0]\n","Path to best model found during training: \n","/content/outputs/2023-06-22/13-09-50/lightning_logs/version_0/checkpoints/9-2939.ckpt\n"]}]},{"cell_type":"code","source":["# copy path file dari baris terakhir output cell di atas.\n","\n","best_ssl_model_ckpt = \"/content/outputs/2023-06-22/13-09-50/lightning_logs/version_0/checkpoints/9-2939.ckpt\""],"metadata":{"id":"nAskwksGLXVF","executionInfo":{"status":"ok","timestamp":1687440244368,"user_tz":-420,"elapsed":4,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["### Supervised learning"],"metadata":{"id":"vBH-NJgyMdLR"}},{"cell_type":"code","source":["!python /content/saint/main.py experiment=supervised \\\n","  experiment.model=saint \\\n","  data.data_folder=/content/saint/data \\\n","  data=bank_sup \\\n","  experiment.pretrained_checkpoint={best_ssl_model_ckpt}"],"metadata":{"id":"kyF5SYkKLY2c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687441282579,"user_tz":-420,"elapsed":1035345,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"9cead47f-f7df-428a-9384-c6e255119394"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-22 13:24:09.167030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-22 13:24:10.181210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/main.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Global seed set to 1234\n","Initializing supervised task using pretrained model:\n","/content/outputs/2023-06-22/13-09-50/lightning_logs/version_0/checkpoints/9-2939.ckpt\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name         | Type             | Params\n","--------------------------------------------------\n","0 | transformer  | Encoder          | 65.0 K\n","1 | embedding    | Embedding        | 3.2 K \n","2 | fc           | Linear           | 165   \n","3 | criterion    | CrossEntropyLoss | 0     \n","4 | train_metric | Accuracy         | 0     \n","5 | valid_metric | Accuracy         | 0     \n","6 | test_metric  | Accuracy         | 0     \n","--------------------------------------------------\n","68.3 K    Trainable params\n","0         Non-trainable params\n","68.3 K    Total params\n","0.273     Total estimated model params size (MB)\n","Global seed set to 1234\n","Epoch 0:  77% 980/1272 [01:30<00:26, 10.86it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  79% 1000/1272 [01:30<00:24, 11.00it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  80% 1020/1272 [01:31<00:22, 11.15it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  82% 1040/1272 [01:32<00:20, 11.29it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  83% 1060/1272 [01:32<00:18, 11.42it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  85% 1080/1272 [01:33<00:16, 11.54it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  86% 1100/1272 [01:34<00:14, 11.66it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  88% 1120/1272 [01:35<00:12, 11.79it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  90% 1140/1272 [01:35<00:11, 11.90it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  91% 1160/1272 [01:36<00:09, 12.00it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  93% 1180/1272 [01:37<00:07, 12.12it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  94% 1200/1272 [01:37<00:05, 12.25it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  96% 1220/1272 [01:38<00:04, 12.38it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  97% 1240/1272 [01:39<00:02, 12.51it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0:  99% 1260/1272 [01:39<00:00, 12.64it/s, loss=1.23, v_num=0, val_loss=1.830, val_acc_epoch=0.141, train_loss_step=0.993]\n","Epoch 0: 100% 1272/1272 [01:40<00:00, 12.71it/s, loss=1.18, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=0.931, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  77% 980/1272 [01:31<00:27, 10.68it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 1:  79% 1000/1272 [01:32<00:25, 10.81it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  80% 1020/1272 [01:33<00:22, 10.96it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  82% 1040/1272 [01:33<00:20, 11.11it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  83% 1060/1272 [01:34<00:18, 11.26it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  85% 1080/1272 [01:34<00:16, 11.40it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  86% 1100/1272 [01:35<00:14, 11.54it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  88% 1120/1272 [01:35<00:13, 11.68it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  90% 1140/1272 [01:36<00:11, 11.82it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  91% 1160/1272 [01:37<00:09, 11.95it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  93% 1180/1272 [01:37<00:07, 12.09it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  94% 1200/1272 [01:38<00:05, 12.21it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  96% 1220/1272 [01:39<00:04, 12.32it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  97% 1240/1272 [01:39<00:02, 12.43it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1:  99% 1260/1272 [01:40<00:00, 12.54it/s, loss=1.15, v_num=0, val_loss=1.200, val_acc_epoch=0.488, train_loss_step=1.230, train_loss_epoch=1.370, train_acc_epoch=0.401]\n","Epoch 1: 100% 1272/1272 [01:41<00:00, 12.58it/s, loss=1.17, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=0.820, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  77% 980/1272 [01:32<00:27, 10.55it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 2:  79% 1000/1272 [01:33<00:25, 10.68it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  80% 1020/1272 [01:34<00:23, 10.83it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  82% 1040/1272 [01:34<00:21, 10.97it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  83% 1060/1272 [01:35<00:19, 11.12it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  85% 1080/1272 [01:35<00:17, 11.26it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  86% 1100/1272 [01:36<00:15, 11.40it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  88% 1120/1272 [01:37<00:13, 11.54it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  90% 1140/1272 [01:37<00:11, 11.68it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  91% 1160/1272 [01:38<00:09, 11.82it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  93% 1180/1272 [01:38<00:07, 11.95it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  94% 1200/1272 [01:39<00:05, 12.08it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  96% 1220/1272 [01:39<00:04, 12.22it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  97% 1240/1272 [01:40<00:02, 12.35it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2:  99% 1260/1272 [01:40<00:00, 12.48it/s, loss=1.24, v_num=0, val_loss=1.180, val_acc_epoch=0.509, train_loss_step=1.230, train_loss_epoch=1.210, train_acc_epoch=0.489]\n","Epoch 2: 100% 1272/1272 [01:41<00:00, 12.54it/s, loss=1.23, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.430, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  77% 980/1272 [01:31<00:27, 10.69it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  79% 1000/1272 [01:32<00:25, 10.81it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  80% 1020/1272 [01:33<00:23, 10.94it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  82% 1040/1272 [01:33<00:20, 11.07it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  83% 1060/1272 [01:34<00:18, 11.20it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  85% 1080/1272 [01:35<00:16, 11.32it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  86% 1100/1272 [01:36<00:15, 11.43it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  88% 1120/1272 [01:37<00:13, 11.54it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  90% 1140/1272 [01:37<00:11, 11.68it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  91% 1160/1272 [01:38<00:09, 11.81it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  93% 1180/1272 [01:38<00:07, 11.95it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  94% 1200/1272 [01:39<00:05, 12.08it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  96% 1220/1272 [01:39<00:04, 12.21it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  97% 1240/1272 [01:40<00:02, 12.34it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3:  99% 1260/1272 [01:41<00:00, 12.47it/s, loss=1.16, v_num=0, val_loss=1.180, val_acc_epoch=0.503, train_loss_step=1.150, train_loss_epoch=1.180, train_acc_epoch=0.504]\n","Epoch 3: 100% 1272/1272 [01:41<00:00, 12.53it/s, loss=1.22, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=1.440, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  77% 980/1272 [01:31<00:27, 10.67it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  79% 1000/1272 [01:32<00:25, 10.81it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  80% 1020/1272 [01:33<00:22, 10.96it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  82% 1040/1272 [01:33<00:20, 11.11it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  83% 1060/1272 [01:34<00:18, 11.25it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  85% 1080/1272 [01:34<00:16, 11.39it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  86% 1100/1272 [01:35<00:14, 11.54it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  88% 1120/1272 [01:35<00:13, 11.68it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  90% 1140/1272 [01:36<00:11, 11.80it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  91% 1160/1272 [01:37<00:09, 11.92it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  93% 1180/1272 [01:38<00:07, 12.04it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  94% 1200/1272 [01:38<00:05, 12.16it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  96% 1220/1272 [01:39<00:04, 12.27it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  97% 1240/1272 [01:40<00:02, 12.37it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4:  99% 1260/1272 [01:41<00:00, 12.46it/s, loss=1.2, v_num=0, val_loss=1.170, val_acc_epoch=0.503, train_loss_step=0.933, train_loss_epoch=1.160, train_acc_epoch=0.510]\n","Epoch 4: 100% 1272/1272 [01:41<00:00, 12.52it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=0.986, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  77% 980/1272 [01:32<00:27, 10.62it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 5:  79% 1000/1272 [01:32<00:25, 10.76it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  80% 1020/1272 [01:33<00:23, 10.91it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  82% 1040/1272 [01:34<00:20, 11.05it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  83% 1060/1272 [01:34<00:18, 11.20it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  85% 1080/1272 [01:35<00:16, 11.34it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  86% 1100/1272 [01:35<00:14, 11.48it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  88% 1120/1272 [01:36<00:13, 11.62it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  90% 1140/1272 [01:36<00:11, 11.76it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  91% 1160/1272 [01:37<00:09, 11.89it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  93% 1180/1272 [01:38<00:07, 12.03it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  94% 1200/1272 [01:38<00:05, 12.16it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  96% 1220/1272 [01:39<00:04, 12.30it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  97% 1240/1272 [01:39<00:02, 12.43it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5:  99% 1260/1272 [01:40<00:00, 12.55it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.516, train_loss_step=1.240, train_loss_epoch=1.150, train_acc_epoch=0.514]\n","Epoch 5: 100% 1272/1272 [01:41<00:00, 12.59it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.200, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  77% 980/1272 [01:33<00:27, 10.54it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 6:  79% 1000/1272 [01:34<00:25, 10.64it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  80% 1020/1272 [01:34<00:23, 10.75it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  82% 1040/1272 [01:35<00:21, 10.89it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  83% 1060/1272 [01:36<00:19, 11.03it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  85% 1080/1272 [01:36<00:17, 11.18it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  86% 1100/1272 [01:37<00:15, 11.32it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  88% 1120/1272 [01:37<00:13, 11.46it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  90% 1140/1272 [01:38<00:11, 11.59it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  91% 1160/1272 [01:38<00:09, 11.73it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  93% 1180/1272 [01:39<00:07, 11.87it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  94% 1200/1272 [01:39<00:05, 12.00it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  96% 1220/1272 [01:40<00:04, 12.13it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  97% 1240/1272 [01:41<00:02, 12.26it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6:  99% 1260/1272 [01:41<00:00, 12.39it/s, loss=1.14, v_num=0, val_loss=1.150, val_acc_epoch=0.521, train_loss_step=1.120, train_loss_epoch=1.150, train_acc_epoch=0.521]\n","Epoch 6: 100% 1272/1272 [01:42<00:00, 12.45it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=0.889, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  77% 980/1272 [01:31<00:27, 10.72it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 7:  79% 1000/1272 [01:32<00:25, 10.86it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  80% 1020/1272 [01:32<00:22, 11.01it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  82% 1040/1272 [01:33<00:20, 11.16it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  83% 1060/1272 [01:33<00:18, 11.30it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  85% 1080/1272 [01:34<00:16, 11.42it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  86% 1100/1272 [01:35<00:14, 11.55it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  88% 1120/1272 [01:35<00:13, 11.67it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  90% 1140/1272 [01:36<00:11, 11.79it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  91% 1160/1272 [01:37<00:09, 11.90it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  93% 1180/1272 [01:38<00:07, 12.00it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  94% 1200/1272 [01:38<00:05, 12.13it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  96% 1220/1272 [01:39<00:04, 12.26it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  97% 1240/1272 [01:40<00:02, 12.39it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7:  99% 1260/1272 [01:40<00:00, 12.52it/s, loss=1.15, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.020, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 7: 100% 1272/1272 [01:41<00:00, 12.58it/s, loss=1.2, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.620, train_loss_epoch=1.140, train_acc_epoch=0.526] \n","Epoch 8:  77% 980/1272 [01:30<00:27, 10.80it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 8:  79% 1000/1272 [01:31<00:24, 10.94it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  80% 1020/1272 [01:31<00:22, 11.09it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  82% 1040/1272 [01:32<00:20, 11.24it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  83% 1060/1272 [01:33<00:18, 11.38it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  85% 1080/1272 [01:33<00:16, 11.53it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  86% 1100/1272 [01:34<00:14, 11.67it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  88% 1120/1272 [01:34<00:12, 11.81it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  90% 1140/1272 [01:35<00:11, 11.95it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  91% 1160/1272 [01:35<00:09, 12.09it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  93% 1180/1272 [01:36<00:07, 12.23it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  94% 1200/1272 [01:37<00:05, 12.36it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  96% 1220/1272 [01:37<00:04, 12.50it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  97% 1240/1272 [01:38<00:02, 12.62it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8:  99% 1260/1272 [01:38<00:00, 12.73it/s, loss=1.1, v_num=0, val_loss=1.150, val_acc_epoch=0.520, train_loss_step=1.380, train_loss_epoch=1.140, train_acc_epoch=0.526]\n","Epoch 8: 100% 1272/1272 [01:39<00:00, 12.77it/s, loss=1.15, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.370, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  77% 980/1272 [01:31<00:27, 10.75it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/294 [00:00<?, ?it/s]\u001b[A\n","Epoch 9:  79% 1000/1272 [01:32<00:25, 10.86it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  80% 1020/1272 [01:32<00:22, 10.97it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  82% 1040/1272 [01:33<00:20, 11.09it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  83% 1060/1272 [01:34<00:18, 11.24it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  85% 1080/1272 [01:34<00:16, 11.38it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  86% 1100/1272 [01:35<00:14, 11.52it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  88% 1120/1272 [01:36<00:13, 11.66it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  90% 1140/1272 [01:36<00:11, 11.80it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  91% 1160/1272 [01:37<00:09, 11.93it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  93% 1180/1272 [01:37<00:07, 12.06it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  94% 1200/1272 [01:38<00:05, 12.20it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  96% 1220/1272 [01:38<00:04, 12.33it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  97% 1240/1272 [01:39<00:02, 12.46it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9:  99% 1260/1272 [01:40<00:00, 12.59it/s, loss=1.05, v_num=0, val_loss=1.160, val_acc_epoch=0.518, train_loss_step=1.270, train_loss_epoch=1.130, train_acc_epoch=0.528]\n","Epoch 9: 100% 1272/1272 [01:40<00:00, 12.65it/s, loss=1.14, v_num=0, val_loss=1.160, val_acc_epoch=0.521, train_loss_step=1.370, train_loss_epoch=1.130, train_acc_epoch=0.530]\n","Epoch 9: 100% 1272/1272 [01:40<00:00, 12.65it/s, loss=1.14, v_num=0, val_loss=1.160, val_acc_epoch=0.521, train_loss_step=1.370, train_loss_epoch=1.130, train_acc_epoch=0.530]\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Testing: 100% 391/391 [00:12<00:00, 31.43it/s]\n","--------------------------------------------------------------------------------\n","DATALOADER:0 TEST RESULTS\n","{'test_acc_best_epoch': 0.527864396572113, 'test_loss': 1.14194917678833}\n","--------------------------------------------------------------------------------\n","Path to best model found during training: \n","/content/outputs/2023-06-22/13-24-12/lightning_logs/version_0/checkpoints/5-5867.ckpt\n"]}]},{"cell_type":"markdown","source":["## Supervised learning only"],"metadata":{"id":"NyPOPTmDOePz"}},{"cell_type":"code","source":["# bare SUP\n","\n","!python /content/saint/main.py experiment=supervised \\\n","  experiment.model=saint \\\n","  data.data_folder=/content/saint/data \\\n","  data=bank_sup"],"metadata":{"id":"dEoRCf56GlGD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687422991755,"user_tz":-420,"elapsed":17276,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"1c81553b-fddc-4098-c414-d26e28293799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-22 08:36:17.143745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-22 08:36:18.588804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/main.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Global seed set to 1234\n","/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n","  warnings.warn(*args, **kwargs)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name         | Type             | Params\n","--------------------------------------------------\n","0 | transformer  | Encoder          | 65.0 K\n","1 | embedding    | Embedding        | 3.2 K \n","2 | fc           | Linear           | 165   \n","3 | criterion    | CrossEntropyLoss | 0     \n","4 | train_metric | AUROC            | 0     \n","--------------------------------------------------\n","68.3 K    Trainable params\n","0         Non-trainable params\n","68.3 K    Total params\n","0.273     Total estimated model params size (MB)\n","Global seed set to 1234\n","Epoch 0: 100% 2/2 [00:00<00:00,  8.45it/s]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 0: 100% 2/2 [00:00<00:00,  4.82it/s, loss=1.71, v_num=0, val_loss=1.700, val_auroc_epoch=0.736, train_loss_step=1.710, train_loss_epoch=1.710, train_auroc_epoch=0.593]\n","Epoch 1: 100% 2/2 [00:00<00:00,  8.94it/s, loss=1.71, v_num=0, val_loss=1.700, val_auroc_epoch=0.736, train_loss_step=1.710, train_loss_epoch=1.710, train_auroc_epoch=0.593]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 1: 100% 2/2 [00:00<00:00,  4.96it/s, loss=1.73, v_num=0, val_loss=1.690, val_auroc_epoch=0.734, train_loss_step=1.740, train_loss_epoch=1.740, train_auroc_epoch=0.473]\n","Epoch 2: 100% 2/2 [00:00<00:00,  8.49it/s, loss=1.73, v_num=0, val_loss=1.690, val_auroc_epoch=0.734, train_loss_step=1.740, train_loss_epoch=1.740, train_auroc_epoch=0.473]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 2: 100% 2/2 [00:00<00:00,  4.79it/s, loss=1.75, v_num=0, val_loss=1.680, val_auroc_epoch=0.741, train_loss_step=1.790, train_loss_epoch=1.790, train_auroc_epoch=0.393]\n","Epoch 3: 100% 2/2 [00:00<00:00,  8.72it/s, loss=1.75, v_num=0, val_loss=1.680, val_auroc_epoch=0.741, train_loss_step=1.790, train_loss_epoch=1.790, train_auroc_epoch=0.393]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 3: 100% 2/2 [00:00<00:00,  4.88it/s, loss=1.73, v_num=0, val_loss=1.670, val_auroc_epoch=0.741, train_loss_step=1.690, train_loss_epoch=1.690, train_auroc_epoch=0.483]\n","Epoch 4: 100% 2/2 [00:00<00:00,  8.54it/s, loss=1.73, v_num=0, val_loss=1.670, val_auroc_epoch=0.741, train_loss_step=1.690, train_loss_epoch=1.690, train_auroc_epoch=0.483]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 4: 100% 2/2 [00:00<00:00,  4.77it/s, loss=1.73, v_num=0, val_loss=1.660, val_auroc_epoch=0.736, train_loss_step=1.720, train_loss_epoch=1.720, train_auroc_epoch=0.463]\n","Epoch 5: 100% 2/2 [00:00<00:00,  8.46it/s, loss=1.73, v_num=0, val_loss=1.660, val_auroc_epoch=0.736, train_loss_step=1.720, train_loss_epoch=1.720, train_auroc_epoch=0.463]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 5: 100% 2/2 [00:00<00:00,  4.68it/s, loss=1.74, v_num=0, val_loss=1.650, val_auroc_epoch=0.730, train_loss_step=1.780, train_loss_epoch=1.780, train_auroc_epoch=0.325]\n","Epoch 6: 100% 2/2 [00:00<00:00,  8.04it/s, loss=1.74, v_num=0, val_loss=1.650, val_auroc_epoch=0.730, train_loss_step=1.780, train_loss_epoch=1.780, train_auroc_epoch=0.325]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 6: 100% 2/2 [00:00<00:00,  4.56it/s, loss=1.71, v_num=0, val_loss=1.640, val_auroc_epoch=0.749, train_loss_step=1.560, train_loss_epoch=1.560, train_auroc_epoch=0.581]\n","Epoch 7: 100% 2/2 [00:00<00:00,  8.76it/s, loss=1.71, v_num=0, val_loss=1.640, val_auroc_epoch=0.749, train_loss_step=1.560, train_loss_epoch=1.560, train_auroc_epoch=0.581]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 7: 100% 2/2 [00:00<00:00,  4.81it/s, loss=1.71, v_num=0, val_loss=1.640, val_auroc_epoch=0.759, train_loss_step=1.660, train_loss_epoch=1.660, train_auroc_epoch=0.531]\n","Epoch 8: 100% 2/2 [00:00<00:00,  8.62it/s, loss=1.71, v_num=0, val_loss=1.640, val_auroc_epoch=0.759, train_loss_step=1.660, train_loss_epoch=1.660, train_auroc_epoch=0.531]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 8: 100% 2/2 [00:00<00:00,  4.75it/s, loss=1.69, v_num=0, val_loss=1.630, val_auroc_epoch=0.752, train_loss_step=1.600, train_loss_epoch=1.600, train_auroc_epoch=0.574]\n","Epoch 9: 100% 2/2 [00:00<00:00,  8.46it/s, loss=1.69, v_num=0, val_loss=1.630, val_auroc_epoch=0.752, train_loss_step=1.600, train_loss_epoch=1.600, train_auroc_epoch=0.574]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n","Epoch 9: 100% 2/2 [00:00<00:00,  4.85it/s, loss=1.69, v_num=0, val_loss=1.630, val_auroc_epoch=0.752, train_loss_step=1.670, train_loss_epoch=1.670, train_auroc_epoch=0.489]\n","Epoch 9: 100% 2/2 [00:00<00:00,  4.23it/s, loss=1.69, v_num=0, val_loss=1.630, val_auroc_epoch=0.752, train_loss_step=1.670, train_loss_epoch=1.670, train_auroc_epoch=0.489]\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Testing: 100% 1/1 [00:00<00:00,  5.34it/s]\n","--------------------------------------------------------------------------------\n","DATALOADER:0 TEST RESULTS\n","{'test_auroc_best_epoch': 0.597684383392334, 'test_loss': 1.5236207246780396}\n","--------------------------------------------------------------------------------\n","Path to best model found during training: \n","/content/outputs/2023-06-22/08-36-21/lightning_logs/version_0/checkpoints/9-9.ckpt\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"gvrjFwH2JpA-"}},{"cell_type":"code","source":["pretrained_checkpoint = \"/content/outputs/2023-06-22/13-24-12/lightning_logs/version_0/checkpoints/5-5867.ckpt\""],"metadata":{"id":"pbNGb90_qzMt","executionInfo":{"status":"ok","timestamp":1687441294383,"user_tz":-420,"elapsed":507,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["!python /content/saint/predict.py experiment=predict \\\n","  experiment.model=saint \\\n","  data=bank_sup \\\n","  data.data_folder=/content/saint/data \\\n","  experiment.pretrained_checkpoint={pretrained_checkpoint} \\\n","  experiment.pred_sav_path=/content/predict.csv"],"metadata":{"id":"2BkcD_bOHJlX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687441337880,"user_tz":-420,"elapsed":41068,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"fbc99512-6c5c-47b2-9955-422802aa2591"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-22 13:41:39.073842: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-22 13:41:40.551238: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/predict.py:15: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","{'seed': 1234, 'transformer': {'num_layers': 6, 'num_heads': 8, 'dropout': 0.1, 'dropout_ff': 0.1, 'embed_dim': 32, 'd_ff': 32, 'cls_token_idx': 0}, 'augmentation': {'prob_cutmix': 0.3, 'alpha': 0.2, 'lambda_pt': 10}, 'optimizer': {'temperature': 0.7, 'proj_head_dim': 128, 'beta_1': 0.9, 'beta_2': 0.99, 'lr': 0.0001, 'weight_decay': 0.01, 'optim': 'adamw', 'metric': 'acc'}, 'preproc': {'data_folder': None, 'train_split': 0.65, 'validation_split': 0.15, 'test_split': 0.2, 'num_supervised_train_data': None}, 'callback': {'monitor': 'val_loss', 'mode': 'min', 'auto_insert_metric_name': False}, 'trainer': {'max_epochs': 10, 'gpus': 1, 'deterministic': True, 'default_root_dir': None, 'resume_from_checkpoint': None}, 'dataloader': {'shuffle_val': False, 'train_bs': 32, 'val_bs': 32, 'test_bs': 16, 'num_workers': 2, 'pin_memory': False}, 'metric': '${optimizer.metric}', 'print_config': False, 'experiment': {'model': 'saint', 'task': 'classification', 'pretrained_checkpoint': '/content/outputs/2023-06-22/13-24-12/lightning_logs/version_0/checkpoints/5-5867.ckpt', 'num_output': 5, 'pred_sav_path': '/content/predict.csv', 'save_prediction': True, 'id_col': 'index', 'target_col': 'target'}, 'data': {'data_folder': '/content/saint/data', 'data_paths': {'train_csv_path': '${data.data_folder}/train.csv', 'train_y_csv_path': '${data.data_folder}/train_y.csv', 'val_csv_path': '${data.data_folder}/val.csv', 'val_y_csv_path': '${data.data_folder}/val_y.csv', 'test_csv_path': '${data.data_folder}/test.csv', 'test_y_csv_path': '${data.data_folder}/test_y.csv'}, 'data_stats': {'no_cat': 1, 'no_num': 49, 'cats': [1]}}}\n","Prediction finished,  csv saved at /content/predict.csv\n"]}]},{"cell_type":"code","source":["pred = pd.read_csv(\"/content/predict.csv\")\n","pred['target'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkms-sdgJFYA","executionInfo":{"status":"ok","timestamp":1687441337881,"user_tz":-420,"elapsed":29,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"0430e2b5-58f2-421a-b7ea-39ccc2a75ae4"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    2842\n","2    2698\n","4    2520\n","3    2301\n","1    2146\n","Name: target, dtype: int64"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["y_truth = pd.read_csv(\"/content/saint/data/test_y.csv\")\n","y_truth['EST9'].value_counts()"],"metadata":{"id":"GK-30CtMQWu0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687441337882,"user_tz":-420,"elapsed":26,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"bf8162da-8673-4164-c8c5-f360479d86ce"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3    2530\n","2    2512\n","4    2509\n","0    2486\n","1    2470\n","Name: EST9, dtype: int64"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["print(classification_report(y_truth, pred['target'], digits = 4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIR6Lt5OUgfr","executionInfo":{"status":"ok","timestamp":1687441337884,"user_tz":-420,"elapsed":24,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"e05e7560-169a-4d58-feae-704aac67b2be"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.6214    0.7104    0.6629      2486\n","           1     0.4692    0.4077    0.4363      2470\n","           2     0.3999    0.4295    0.4142      2512\n","           3     0.4646    0.4225    0.4426      2530\n","           4     0.6671    0.6700    0.6685      2509\n","\n","    accuracy                         0.5279     12507\n","   macro avg     0.5244    0.5280    0.5249     12507\n","weighted avg     0.5243    0.5279    0.5248     12507\n","\n"]}]},{"cell_type":"code","source":["cm = confusion_matrix(y_truth, pred['target'])\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"a6SjyIUUW5Lk","executionInfo":{"status":"ok","timestamp":1687441337885,"user_tz":-420,"elapsed":21,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"44c10638-6037-4511-d64c-2ce68119778c"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: >"]},"metadata":{},"execution_count":65},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}