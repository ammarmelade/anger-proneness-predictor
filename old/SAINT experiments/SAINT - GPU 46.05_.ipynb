{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyPwGAofqaocmINdOf3C6gU3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Preliminaries"],"metadata":{"id":"6ZiHKXJ0JQ2y"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive/')"],"metadata":{"id":"irMRi0gI9vH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686511634676,"user_tz":-420,"elapsed":20237,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"ee91fec2-931d-4b6f-fd21-fad85808c732"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wF_EZuxx8-UB","executionInfo":{"status":"ok","timestamp":1686511638636,"user_tz":-420,"elapsed":3979,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"82e292da-426b-42b4-c974-9a117c93ba61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'saint'...\n","remote: Enumerating objects: 664, done.\u001b[K\n","remote: Total 664 (delta 0), reused 0 (delta 0), pack-reused 664\u001b[K\n","Receiving objects: 100% (664/664), 17.00 MiB | 13.06 MiB/s, done.\n","Resolving deltas: 100% (364/364), done.\n"]}],"source":["!git clone https://github.com/ogunlao/saint.git"]},{"cell_type":"code","source":["!pip install pytorch-lightning==1.3.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZ4VpFXm7GDp","executionInfo":{"status":"ok","timestamp":1686511933129,"user_tz":-420,"elapsed":29249,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"8daaf278-a83e-40e9-9087-6f10a1f52078"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning==1.3.2\n","  Downloading pytorch_lightning-1.3.2-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.7/805.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (1.22.4)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (2.0.1+cu118)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (0.18.3)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (4.65.0)\n","Collecting PyYAML<=5.4.1,>=5.1 (from pytorch-lightning==1.3.2)\n","  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.1/175.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (2023.4.0)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (2.12.2)\n","Collecting torchmetrics>=0.2.0 (from pytorch-lightning==1.3.2)\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyDeprecate==0.3.0 (from pytorch-lightning==1.3.2)\n","  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.3.2) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (2.27.1)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.54.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.40.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch-lightning==1.3.2) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch-lightning==1.3.2) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch-lightning==1.3.2) (16.0.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.2) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->pytorch-lightning==1.3.2) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.2) (3.2.2)\n","Building wheels for collected packages: PyYAML\n","  Building wheel for PyYAML (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.4.1-cp310-cp310-linux_x86_64.whl size=45658 sha256=529feeaabf25b7c7f6d7a46356df4ab5afde9325370bb1e8ec24e63ba58fc473\n","  Stored in directory: /root/.cache/pip/wheels/c7/0d/22/696ee92245ad710f506eee79bb05c740d8abccd3ecdb778683\n","Successfully built PyYAML\n","Installing collected packages: PyYAML, pyDeprecate, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","Successfully installed PyYAML-5.4.1 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 pyDeprecate-0.3.0 pytorch-lightning-1.3.2 torchmetrics-0.11.4 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["# !pip3 install -r \"/content/saint/requirements.txt\""],"metadata":{"id":"0ECBnzW59KNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install scikit-learn==0.24.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czKgW7eW7lTi","executionInfo":{"status":"ok","timestamp":1686512351596,"user_tz":-420,"elapsed":418490,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"f9d27d57-20b0-408f-e639-6a7b34639f87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-learn==0.24.2\n","  Downloading scikit-learn-0.24.2.tar.gz (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.22.4)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.10.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==0.24.2) (3.1.0)\n","Building wheels for collected packages: scikit-learn\n","  Building wheel for scikit-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install scipy==1.5.4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PdZC8Xhx7rEc","executionInfo":{"status":"ok","timestamp":1686512524014,"user_tz":-420,"elapsed":172463,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"3ab6a22c-681e-4647-f5c6-474371bcbcbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scipy==1.5.4\n","  Downloading scipy-1.5.4.tar.gz (25.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/25.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"]}]},{"cell_type":"code","source":["!pip install tensorboard==2.4.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QzrvzYGU7q_C","executionInfo":{"status":"ok","timestamp":1686512539785,"user_tz":-420,"elapsed":15828,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"9a150161-c891-40ab-e533-ea35fe95c054"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard==2.4.1\n","  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.54.0)\n","Collecting google-auth<2,>=1.6.3 (from tensorboard==2.4.1)\n","  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.4.1)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (3.4.3)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.22.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (2.27.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (67.7.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.4.1) (0.40.0)\n","Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard==2.4.1)\n","  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<2,>=1.6.3->tensorboard==2.4.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.4.1) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard==2.4.1) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard==2.4.1) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.4.1) (3.2.2)\n","Installing collected packages: cachetools, google-auth, google-auth-oauthlib, tensorboard\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 5.3.0\n","    Uninstalling cachetools-5.3.0:\n","      Successfully uninstalled cachetools-5.3.0\n","  Attempting uninstall: google-auth\n","    Found existing installation: google-auth 2.17.3\n","    Uninstalling google-auth-2.17.3:\n","      Successfully uninstalled google-auth-2.17.3\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-api-core 2.11.0 requires google-auth<3.0dev,>=2.14.1, but you have google-auth 1.35.0 which is incompatible.\n","google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 1.35.0 which is incompatible.\n","tensorflow 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cachetools-4.2.4 google-auth-1.35.0 google-auth-oauthlib-0.4.6 tensorboard-2.4.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install tensorboard-plugin-wit==1.8.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNz-mi0s7q0l","executionInfo":{"status":"ok","timestamp":1686512545473,"user_tz":-420,"elapsed":5728,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"fd5cfa31-74d0-4c94-c7fd-0bb711cec1e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard-plugin-wit==1.8.0\n","  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.2/781.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard-plugin-wit\n","  Attempting uninstall: tensorboard-plugin-wit\n","    Found existing installation: tensorboard-plugin-wit 1.8.1\n","    Uninstalling tensorboard-plugin-wit-1.8.1:\n","      Successfully uninstalled tensorboard-plugin-wit-1.8.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.12.0 requires tensorboard<2.13,>=2.12, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorboard-plugin-wit-1.8.0\n"]}]},{"cell_type":"code","source":["!pip install torch==1.8.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sk55Z5-d75xp","executionInfo":{"status":"ok","timestamp":1686512547264,"user_tz":-420,"elapsed":1819,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"53639bc9-8e75-4a29-d463-6f5df05bc954"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.1\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install torchmetrics==0.3.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"832RK6OB78_Y","executionInfo":{"status":"ok","timestamp":1686512554994,"user_tz":-420,"elapsed":7752,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"1f3b9e64-e084-41f9-ec03-849fff94a978"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics==0.3.2\n","  Downloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/274.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.3.2) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics==0.3.2) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics==0.3.2) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.1->torchmetrics==0.3.2) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3.1->torchmetrics==0.3.2) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.1->torchmetrics==0.3.2) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.1->torchmetrics==0.3.2) (1.3.0)\n","Installing collected packages: torchmetrics\n","  Attempting uninstall: torchmetrics\n","    Found existing installation: torchmetrics 0.11.4\n","    Uninstalling torchmetrics-0.11.4:\n","      Successfully uninstalled torchmetrics-0.11.4\n","Successfully installed torchmetrics-0.3.2\n"]}]},{"cell_type":"code","source":["!pip install torchtext==0.6.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cBUbpbK7_ji","executionInfo":{"status":"ok","timestamp":1686512562513,"user_tz":-420,"elapsed":7543,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"64664873-04c0-4c19-f101-7c7b74c77142"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.27.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.22.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Collecting sentencepiece (from torchtext==0.6.0)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6.0) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.2\n","    Uninstalling torchtext-0.15.2:\n","      Successfully uninstalled torchtext-0.15.2\n","Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"]}]},{"cell_type":"code","source":["!pip install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WIYK5adF7_et","executionInfo":{"status":"ok","timestamp":1686512568601,"user_tz":-420,"elapsed":6104,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"31bc02a2-3d66-41d6-98e9-06d02c73662b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"]}]},{"cell_type":"code","source":["!pip install hydra-core"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":471},"id":"S6QGqYdU8Frx","executionInfo":{"status":"ok","timestamp":1686512580186,"user_tz":-420,"elapsed":11605,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"1976a2da-85d4-40d8-9d98-650dc098e33a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.1)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (5.4.1)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=d6fd23553251f35bea6e5a04251513a7012aa75c5b20fdaa42c2b8627f9a6704\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n","Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install ruamel_yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZpR1cNo8IRD","executionInfo":{"status":"ok","timestamp":1686512591463,"user_tz":-420,"elapsed":11316,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"ecde7ac3-1875-408d-ec41-87fea57d3754"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ruamel_yaml\n","  Downloading ruamel.yaml-0.17.31-py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel_yaml)\n","  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel_yaml\n","Successfully installed ruamel.yaml.clib-0.2.7 ruamel_yaml-0.17.31\n"]}]},{"cell_type":"code","source":["# !pip install torch --upgrade torch\n","# !pip install torch --upgrade pytorch-lightning"],"metadata":{"id":"RMjvVdfYITxk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !nvcc --version"],"metadata":{"id":"WEdpJXk_I_lg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","\n","print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VEnYWP1KH_Z","executionInfo":{"status":"ok","timestamp":1686512597082,"user_tz":-420,"elapsed":5680,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"44197c26-bc2f-4c00-f1e2-ccafdd88781d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["\n","# Setting up parameters"],"metadata":{"id":"Q5gQs6SaILhx"}},{"cell_type":"code","source":["from ruamel.yaml import YAML "],"metadata":{"id":"VnOHG2rCImIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**IMPORTANT : EDIT FILE-FILE INI DULU SEBELUM RUN**\n","\n","Cara editnya : double-click file yg mau di edit di \"Files\" (tab kiri colab) ato klik link-link dibawah, terus ctrl-s buat save.\n","\n","```1. /content/saint/configs/config.yaml, line 46```\n","\n","```\n","trainer:\n","  max_epochs: 100 # default is 100\n","  # gpus: 0\n","  accelerator: auto\n","  deterministic: true\n","  default_root_dir: null\n","  # resume_from_checkpoint: null\n","```\n","\n","```2. /content/saint/configs/data/bank_ssl.yaml, line 10```\n","```\n","data_stats:\n","  no_cat: 1\n","  no_num: 49\n","  cats: [1]\n","```\n","\n","```3. /content/saint/configs/data/bank_sup.yaml, line 10```\n","\n","```\n","data_stats:\n","  no_cat: 1\n","  no_num: 49\n","  cats: [1]\n","```\n","\n","```4. /content/saint/configs/experiment/supervised.yaml```\n","\n","```\n","experiment: supervised\n","task: classification # {classification, regression}\n","model: saint\n","num_output: 5 # no of output neurons: 1 for binary classification num of classes in target for multiclass}\n","freeze_encoder: false # freeze transformer layer\n","pretrained_checkpoint: null #checkpoints/lightning_logs/version_7/checkpoints/epoch=0-step=1.ckpt\n","```"],"metadata":{"id":"fdYj59RZzVWT"}},{"cell_type":"code","source":["config_path = 'saint/configs/config.yaml'\n","\n","yaml = YAML(typ='safe')\n","with open(config_path) as f:\n","  args = yaml.load(f)\n","\n","print(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3yBXKWlIOjL","executionInfo":{"status":"ok","timestamp":1686512597646,"user_tz":-420,"elapsed":26,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"fe402d77-a90c-464b-d9cf-5b5b5d8600bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'defaults': ['_self_', {'experiment': 'supervised'}, {'data': 'bank_sup'}], 'seed': 1234, 'transformer': {'num_layers': 6, 'num_heads': 8, 'dropout': 0.1, 'dropout_ff': 0.1, 'embed_dim': 32, 'd_ff': 32, 'cls_token_idx': 0}, 'augmentation': {'prob_cutmix': 0.3, 'alpha': 0.2, 'lambda_pt': 10}, 'optimizer': {'temperature': 0.7, 'proj_head_dim': 128, 'beta_1': 0.9, 'beta_2': 0.99, 'lr': 0.0001, 'weight_decay': 0.01, 'optim': 'adamw', 'metric': 'auroc'}, 'preproc': {'data_folder': None, 'train_split': 0.65, 'validation_split': 0.15, 'test_split': 0.2, 'num_supervised_train_data': None}, 'callback': {'monitor': 'val_loss', 'mode': 'min', 'auto_insert_metric_name': False}, 'trainer': {'max_epochs': 100, 'gpus': 0, 'deterministic': True, 'default_root_dir': None, 'resume_from_checkpoint': None}, 'dataloader': {'shuffle_val': False, 'train_bs': 32, 'val_bs': 32, 'test_bs': 16, 'num_workers': 2, 'pin_memory': False}, 'metric': '${optimizer.metric}', 'print_config': False}\n"]}]},{"cell_type":"markdown","source":["# Data preprocessing"],"metadata":{"id":"mIFvOAGlIueV"}},{"cell_type":"code","source":["data_folder = \"/content/saint/data\"\n","\n","os.mkdir(\"/content/saint/data\")"],"metadata":{"id":"b2yZLsEkI1Ex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv(\"/content/drive/MyDrive/SEM4/Research Method/RM Kel 19 Experiment/data-final.csv\", sep='\\t')\n","\n","print(dataset.shape)\n","dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"0NCa-gD39lta","executionInfo":{"status":"ok","timestamp":1686512623813,"user_tz":-420,"elapsed":26184,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"b2e722d1-db91-4745-9793-8ea0aed7013f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1015341, 110)\n"]},{"output_type":"execute_result","data":{"text/plain":["   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n","0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   \n","1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   \n","2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   \n","3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   \n","4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   \n","\n","              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n","0  2016-03-03 02:01:01    768.0   1024.0          9.0       234.0          6   \n","1  2016-03-03 02:01:20   1360.0    768.0         12.0       179.0         11   \n","2  2016-03-03 02:01:56   1366.0    768.0          3.0       186.0          7   \n","3  2016-03-03 02:02:02   1920.0   1200.0        186.0       219.0          7   \n","4  2016-03-03 02:02:57   1366.0    768.0          8.0       315.0         17   \n","\n","   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n","0    1       GB               51.5448                 0.1991  \n","1    1       MY                3.1698                101.706  \n","2    1       GB               54.9119                -1.3833  \n","3    1       GB                 51.75                  -1.25  \n","4    2       KE                   1.0                   38.0  \n","\n","[5 rows x 110 columns]"],"text/html":["\n","  <div id=\"df-58fa9dc2-9dd9-40ae-b152-a79b07a00913\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EXT1</th>\n","      <th>EXT2</th>\n","      <th>EXT3</th>\n","      <th>EXT4</th>\n","      <th>EXT5</th>\n","      <th>EXT6</th>\n","      <th>EXT7</th>\n","      <th>EXT8</th>\n","      <th>EXT9</th>\n","      <th>EXT10</th>\n","      <th>...</th>\n","      <th>dateload</th>\n","      <th>screenw</th>\n","      <th>screenh</th>\n","      <th>introelapse</th>\n","      <th>testelapse</th>\n","      <th>endelapse</th>\n","      <th>IPC</th>\n","      <th>country</th>\n","      <th>lat_appx_lots_of_err</th>\n","      <th>long_appx_lots_of_err</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:01:01</td>\n","      <td>768.0</td>\n","      <td>1024.0</td>\n","      <td>9.0</td>\n","      <td>234.0</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>GB</td>\n","      <td>51.5448</td>\n","      <td>0.1991</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:01:20</td>\n","      <td>1360.0</td>\n","      <td>768.0</td>\n","      <td>12.0</td>\n","      <td>179.0</td>\n","      <td>11</td>\n","      <td>1</td>\n","      <td>MY</td>\n","      <td>3.1698</td>\n","      <td>101.706</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:01:56</td>\n","      <td>1366.0</td>\n","      <td>768.0</td>\n","      <td>3.0</td>\n","      <td>186.0</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>GB</td>\n","      <td>54.9119</td>\n","      <td>-1.3833</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:02:02</td>\n","      <td>1920.0</td>\n","      <td>1200.0</td>\n","      <td>186.0</td>\n","      <td>219.0</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>GB</td>\n","      <td>51.75</td>\n","      <td>-1.25</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>2016-03-03 02:02:57</td>\n","      <td>1366.0</td>\n","      <td>768.0</td>\n","      <td>8.0</td>\n","      <td>315.0</td>\n","      <td>17</td>\n","      <td>2</td>\n","      <td>KE</td>\n","      <td>1.0</td>\n","      <td>38.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 110 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58fa9dc2-9dd9-40ae-b152-a79b07a00913')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-58fa9dc2-9dd9-40ae-b152-a79b07a00913 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-58fa9dc2-9dd9-40ae-b152-a79b07a00913');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["data = dataset.drop(list(dataset)[50:], axis=1)\n","\n","print(data.shape)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"kKU71FbL-CH1","executionInfo":{"status":"ok","timestamp":1686516140725,"user_tz":-420,"elapsed":347,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"e7d1b874-be76-48bb-8435-d9b3b9dc628b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1015341, 50)\n"]},{"output_type":"execute_result","data":{"text/plain":["   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  OPN1  \\\n","0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   5.0   \n","1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   1.0   \n","2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   5.0   \n","3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   4.0   \n","4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   5.0   \n","\n","   OPN2  OPN3  OPN4  OPN5  OPN6  OPN7  OPN8  OPN9  OPN10  \n","0   1.0   4.0   1.0   4.0   1.0   5.0   3.0   4.0    5.0  \n","1   2.0   4.0   2.0   3.0   1.0   4.0   2.0   5.0    3.0  \n","2   1.0   2.0   1.0   4.0   2.0   5.0   3.0   4.0    4.0  \n","3   2.0   5.0   2.0   3.0   1.0   4.0   4.0   3.0    3.0  \n","4   1.0   5.0   1.0   5.0   1.0   5.0   3.0   5.0    5.0  \n","\n","[5 rows x 50 columns]"],"text/html":["\n","  <div id=\"df-7cc666bf-4779-4666-93bf-84404770c2b8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EXT1</th>\n","      <th>EXT2</th>\n","      <th>EXT3</th>\n","      <th>EXT4</th>\n","      <th>EXT5</th>\n","      <th>EXT6</th>\n","      <th>EXT7</th>\n","      <th>EXT8</th>\n","      <th>EXT9</th>\n","      <th>EXT10</th>\n","      <th>...</th>\n","      <th>OPN1</th>\n","      <th>OPN2</th>\n","      <th>OPN3</th>\n","      <th>OPN4</th>\n","      <th>OPN5</th>\n","      <th>OPN6</th>\n","      <th>OPN7</th>\n","      <th>OPN8</th>\n","      <th>OPN9</th>\n","      <th>OPN10</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>4.0</td>\n","      <td>2.0</td>\n","      <td>5.0</td>\n","      <td>2.0</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>...</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 50 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cc666bf-4779-4666-93bf-84404770c2b8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7cc666bf-4779-4666-93bf-84404770c2b8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7cc666bf-4779-4666-93bf-84404770c2b8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["for i in data.columns:\n","  data = data[(data[i].notna()) & (data[i] != 0)]\n","\n","print(data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z75-zCjK-IiC","executionInfo":{"status":"ok","timestamp":1686516156007,"user_tz":-420,"elapsed":13246,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"9eb7ba9c-32c6-4050-e20f-59148a4904b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(874434, 50)\n"]}]},{"cell_type":"code","source":["data = data.astype(int)"],"metadata":{"id":"v6-PfEfr9vjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['EST9'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fK-gKGep-GKA","executionInfo":{"status":"ok","timestamp":1686516156688,"user_tz":-420,"elapsed":9,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"2311c30d-7b23-4150-b987-abba9b1d2611"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    247851\n","2    199050\n","3    182001\n","5    133152\n","1    112380\n","Name: EST9, dtype: int64"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["data = data[:10000]"],"metadata":{"id":"rOAEEVuG1oC5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = data.drop(columns=['EST9'])\n","y = data['EST9']"],"metadata":{"id":"f9Arorto-KIy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = y - 1"],"metadata":{"id":"QN7RPmy9S8X9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from saint.src.dataset import generate_splits, preprocess"],"metadata":{"id":"XYfjIiOeJe91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_supervised_train_data = 2000\n","\n","sup_train_indices, val_indices, test_indices, ssl_train_indices = generate_splits(len(x), num_supervised_train_data, args['preproc']['validation_split'], args['preproc']['test_split'], args['seed'],)"],"metadata":{"id":"sBdu-PJLJjt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_proc, y_proc, no_num, no_cat, cats  = preprocess(x, y, args['transformer']['cls_token_idx'])"],"metadata":{"id":"1ldx0xi8J9mT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('no of numerical columns: ', no_num)\n","print('no of categorical columns: ', no_cat)\n","\n","print('list of categories in each categorical column: ', cats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99TtxxqOKEMK","executionInfo":{"status":"ok","timestamp":1686516199750,"user_tz":-420,"elapsed":398,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"2ab2a649-f785-4d62-e3f6-0f5ef7f45cca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["no of numerical columns:  49\n","no of categorical columns:  1\n","list of categories in each categorical column:  [1]\n"]}]},{"cell_type":"code","source":["train_df, train_y   = x_proc.iloc[sup_train_indices], y_proc.iloc[sup_train_indices]\n","val_df, val_y       = x_proc.iloc[val_indices], y_proc.iloc[val_indices]\n","test_df, test_y     = x_proc.iloc[test_indices], y_proc.iloc[test_indices]"],"metadata":{"id":"zO_CGazRKIlS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ssl, train_ssl_y = None, None\n","\n","if num_supervised_train_data != 'all':\n","    train_ssl, train_ssl_y = x_proc.iloc[ssl_train_indices], y_proc.iloc[ssl_train_indices]"],"metadata":{"id":"xdM8JYynKciy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.to_csv('/content/saint/data/train.csv' , index=False)\n","train_y.to_csv('/content/saint/data/train_y.csv' , index=False)\n","val_df.to_csv('/content/saint/data/val.csv' , index=False)\n","val_y.to_csv('/content/saint/data/val_y.csv' , index=False)\n","test_df.to_csv('/content/saint/data/test.csv' , index=False)\n","test_y.to_csv('/content/saint/data/test_y.csv' , index=False)\n","\n","if train_ssl is not None:\n","   train_ssl.to_csv('/content/saint/data/train_ssl.csv' , index=False)\n","\n","if train_ssl_y is not None:\n","  train_ssl_y.to_csv('/content/saint/data/train_ssl_y.csv' , index=False)"],"metadata":{"id":"xn-T7swhKpmA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SAINT training"],"metadata":{"id":"XK3XHgVCGfOm"}},{"cell_type":"code","source":["num_gpus = 1"],"metadata":{"id":"mqJKcN-ZNr7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ[\"HYDRA_FULL_ERROR\"] = \"1\""],"metadata":{"id":"uMwBMOpT51E3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Self-supervised learning + supervised learning"],"metadata":{"id":"rZyNJ8mpOm6A"}},{"cell_type":"code","source":["# Self-Supervised Learning\n","\n","!python /content/saint/main.py experiment=self-supervised \\\n","  experiment.model=saint \\\n","  data.data_folder=/content/saint/data \\\n","  data=bank_ssl"],"metadata":{"id":"tVpqTt4RLUV7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686516314812,"user_tz":-420,"elapsed":106859,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"ff19bea9-4eb8-4724-e5ab-9621b4fdc9fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-11 20:43:32.216106: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-11 20:43:34.254182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/main.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Global seed set to 1234\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","\n","  | Name                | Type            | Params\n","--------------------------------------------------------\n","0 | transformer         | Encoder         | 65.0 K\n","1 | embedding           | Embedding       | 3.2 K \n","2 | contrastive_loss_fn | ContrastiveLoss | 409 K \n","3 | denoising_loss_fn   | DenoisingLoss   | 1.6 K \n","--------------------------------------------------------\n","479 K     Trainable params\n","0         Non-trainable params\n","479 K     Total params\n","1.918     Total estimated model params size (MB)\n","Global seed set to 1234\n","Epoch 0:  75% 141/188 [01:11<00:23,  1.96it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/47 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  76% 143/188 [01:12<00:22,  1.98it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:   4% 2/47 [00:00<00:09,  4.70it/s]\u001b[A\n","Epoch 0:  77% 145/188 [01:12<00:21,  2.00it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:   9% 4/47 [00:00<00:07,  5.88it/s]\u001b[A\n","Epoch 0:  78% 147/188 [01:12<00:20,  2.02it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  13% 6/47 [00:01<00:06,  6.18it/s]\u001b[A\n","Epoch 0:  79% 149/188 [01:13<00:19,  2.03it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  17% 8/47 [00:01<00:06,  6.03it/s]\u001b[A\n","Epoch 0:  80% 151/188 [01:13<00:18,  2.05it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  21% 10/47 [00:01<00:06,  5.67it/s]\u001b[A\n","Epoch 0:  81% 153/188 [01:13<00:16,  2.07it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  26% 12/47 [00:02<00:06,  5.42it/s]\u001b[A\n","Epoch 0:  82% 155/188 [01:14<00:15,  2.08it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  30% 14/47 [00:02<00:07,  4.50it/s]\u001b[A\n","Epoch 0:  84% 157/188 [01:14<00:14,  2.09it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  34% 16/47 [00:03<00:07,  4.19it/s]\u001b[A\n","Epoch 0:  85% 159/188 [01:15<00:13,  2.11it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  38% 18/47 [00:03<00:06,  4.18it/s]\u001b[A\n","Epoch 0:  86% 161/188 [01:15<00:12,  2.12it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  43% 20/47 [00:04<00:06,  4.01it/s]\u001b[A\n","Epoch 0:  87% 163/188 [01:16<00:11,  2.13it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  47% 22/47 [00:04<00:06,  4.04it/s]\u001b[A\n","Epoch 0:  88% 165/188 [01:16<00:10,  2.14it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  51% 24/47 [00:05<00:05,  3.97it/s]\u001b[A\n","Epoch 0:  89% 167/188 [01:17<00:09,  2.16it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  55% 26/47 [00:05<00:05,  4.04it/s]\u001b[A\n","Epoch 0:  90% 169/188 [01:17<00:08,  2.17it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  60% 28/47 [00:06<00:04,  4.04it/s]\u001b[A\n","Epoch 0:  91% 171/188 [01:18<00:07,  2.18it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  64% 30/47 [00:06<00:04,  4.17it/s]\u001b[A\n","Epoch 0:  92% 173/188 [01:18<00:06,  2.19it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  68% 32/47 [00:07<00:03,  4.27it/s]\u001b[A\n","Epoch 0:  93% 175/188 [01:19<00:05,  2.21it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  72% 34/47 [00:07<00:03,  4.15it/s]\u001b[A\n","Epoch 0:  94% 177/188 [01:19<00:04,  2.22it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  77% 36/47 [00:08<00:02,  4.41it/s]\u001b[A\n","Epoch 0:  95% 179/188 [01:20<00:04,  2.23it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  81% 38/47 [00:08<00:01,  4.93it/s]\u001b[A\n","Epoch 0:  96% 181/188 [01:20<00:03,  2.25it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  85% 40/47 [00:08<00:01,  5.63it/s]\u001b[A\n","Epoch 0:  97% 183/188 [01:20<00:02,  2.26it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  89% 42/47 [00:08<00:00,  6.08it/s]\u001b[A\n","Epoch 0:  98% 185/188 [01:21<00:01,  2.28it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  94% 44/47 [00:09<00:00,  6.21it/s]\u001b[A\n","Epoch 0:  99% 187/188 [01:21<00:00,  2.29it/s, loss=593, v_num=0, val_loss_epoch=684.0, train_loss_step=589.0]\n","Validating:  98% 46/47 [00:09<00:00,  6.06it/s]\u001b[A\n","Epoch 0: 100% 188/188 [01:21<00:00,  2.30it/s, loss=593, v_num=0, val_loss_epoch=598.0, train_loss_step=552.0, train_loss_epoch=606.0, val_loss_step=602.0]\n","Epoch 1:  11% 20/188 [00:09<01:20,  2.09it/s, loss=592, v_num=0, val_loss_epoch=598.0, train_loss_step=571.0, train_loss_epoch=606.0, val_loss_step=602.0]/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  warnings.warn(*args, **kwargs)\n","Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f63bedc3ac0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n","Path to best model found during training: \n","/content/outputs/2023-06-11/20-43-39/lightning_logs/version_0/checkpoints/0-140.ckpt\n","Epoch 1:  11% 20/188 [00:10<01:27,  1.92it/s, loss=592, v_num=0, val_loss_epoch=598.0, train_loss_step=571.0, train_loss_epoch=606.0, val_loss_step=602.0]\n"]}]},{"cell_type":"code","source":["# copy path file dari baris terakhir output cell di atas.\n","\n","best_ssl_model_ckpt = \"/content/outputs/2023-06-11/19-48-11/lightning_logs/version_0/checkpoints/6-104.ckpt\""],"metadata":{"id":"nAskwksGLXVF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**WARNING : Edit dulu**\n","\n","```1. /content/saint/utils/utils.py, line 42```\n","```\n","def auroc(self):\n","  return AUROC(num_classes=self.num_classes, task='multiclass')\n","```\n","```2. /content/saint/src/trainer.py, line 81```\n","```\n","def on_training_epoch_end(self, training_step_outputs):\n","```\n","```4. /content/saint/src/trainer.py, line 107```\n","```\n","def on_test_epoch_end(self):\n","```\n","```5. /content/saint/src/trainer.py, line 16```\n","```\n","super().__init__()\n","self.validation_step_outputs = []\n","self.transformer = transformer\n","```\n","```6. /content/saint/src/trainer.py, line 88```\n","```\n","def validation_step(self, batch, batch_idx):\n","    val_loss = self._shared_step(batch, self.valid_metric)\n","\n","    # log the outputs!\n","    self.log(f'val_loss', val_loss, on_step=False, \n","              on_epoch=True, prog_bar=True, logger=True)\n","    \n","    self.log(f'val_{self.metric}_epoch', self.valid_metric.compute(), prog_bar=True,)\n","    \n","    self.validation_step_outputs.append(val_loss)\n","    return val_loss\n","```\n","```7. /content/saint/src/trainer.py, line 98```\n","```\n","def on_validation_epoch_end(self):\n","    self.log(f'val_{self.metric}_epoch', self.valid_metric.compute(), prog_bar=True,)\n","\n","    # reset after each epoch\n","    self.valid_metric.reset()\n","    \n","    epoch_average = torch.stack(self.validation_step_outputs).mean()\n","    self.log(\"validation_epoch_average\", epoch_average)\n","    self.validation_step_outputs.clear()  # free memory\n","```\n","```Reference : https://github.com/Lightning-AI/lightning/discussions/17182```\n","\n","```8. /content/saint/src/train.py, line 42```\n","```\n","trainer.fit(model, dataloaders['train_loader'], dataloaders['validation_loader'])\n","```"],"metadata":{"id":"pl-QqhdQBdvr"}},{"cell_type":"code","source":["os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""],"metadata":{"id":"I9ogLvZUJHr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SUP from SSL\n","\n","!python /content/saint/main.py experiment=supervised \\\n","  experiment.model=saint \\\n","  data.data_folder=/content/saint/data \\\n","  data=bank_sup \\\n","  experiment.pretrained_checkpoint={best_ssl_model_ckpt}"],"metadata":{"id":"kyF5SYkKLY2c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686515980676,"user_tz":-420,"elapsed":278031,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"2b64d7de-a36a-44de-ccdc-b4eea5a887eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-11 20:35:06.465433: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-11 20:35:08.182616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/main.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Global seed set to 1234\n","Initializing supervised task using pretrained model:\n","/content/outputs/2023-06-11/19-48-11/lightning_logs/version_0/checkpoints/6-104.ckpt\n","GPU available: False, used: False\n","TPU available: False, using: 0 TPU cores\n","\n","  | Name         | Type             | Params\n","--------------------------------------------------\n","0 | transformer  | Encoder          | 65.0 K\n","1 | embedding    | Embedding        | 3.2 K \n","2 | fc           | Linear           | 165   \n","3 | criterion    | CrossEntropyLoss | 0     \n","4 | train_metric | Accuracy         | 0     \n","5 | valid_metric | Accuracy         | 0     \n","6 | test_metric  | Accuracy         | 0     \n","--------------------------------------------------\n","68.3 K    Trainable params\n","0         Non-trainable params\n","68.3 K    Total params\n","0.273     Total estimated model params size (MB)\n","Global seed set to 1234\n","Epoch 0:  58% 7/12 [00:02<00:02,  2.46it/s, loss=1.68, v_num=0, val_loss=1.760, val_acc_epoch=0.250, train_loss_step=1.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 0:  75% 9/12 [00:03<00:01,  2.84it/s, loss=1.68, v_num=0, val_loss=1.760, val_acc_epoch=0.250, train_loss_step=1.520]\n","Validating:  40% 2/5 [00:00<00:00,  4.71it/s]\u001b[A\n","Epoch 0:  92% 11/12 [00:03<00:00,  3.18it/s, loss=1.68, v_num=0, val_loss=1.760, val_acc_epoch=0.250, train_loss_step=1.520]\n","Validating:  80% 4/5 [00:00<00:00,  6.23it/s]\u001b[A\n","Epoch 0: 100% 12/12 [00:03<00:00,  3.16it/s, loss=1.68, v_num=0, val_loss=1.680, val_acc_epoch=0.253, train_loss_step=1.850, train_loss_epoch=1.660, train_acc_epoch=0.235]\n","Epoch 1:  67% 8/12 [00:02<00:01,  3.17it/s, loss=1.63, v_num=0, val_loss=1.680, val_acc_epoch=0.253, train_loss_step=1.430, train_loss_epoch=1.660, train_acc_epoch=0.235]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.89it/s]\u001b[A\n","Epoch 1:  83% 10/12 [00:02<00:00,  3.54it/s, loss=1.63, v_num=0, val_loss=1.680, val_acc_epoch=0.253, train_loss_step=1.430, train_loss_epoch=1.660, train_acc_epoch=0.235]\n","Epoch 1: 100% 12/12 [00:03<00:00,  3.84it/s, loss=1.63, v_num=0, val_loss=1.660, val_acc_epoch=0.193, train_loss_step=1.350, train_loss_epoch=1.610, train_acc_epoch=0.230]\n","Epoch 2:  67% 8/12 [00:01<00:00,  4.78it/s, loss=1.59, v_num=0, val_loss=1.660, val_acc_epoch=0.193, train_loss_step=1.490, train_loss_epoch=1.610, train_acc_epoch=0.230]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.73it/s]\u001b[A\n","Epoch 2:  83% 10/12 [00:01<00:00,  5.02it/s, loss=1.59, v_num=0, val_loss=1.660, val_acc_epoch=0.193, train_loss_step=1.490, train_loss_epoch=1.610, train_acc_epoch=0.230]\n","Epoch 2: 100% 12/12 [00:02<00:00,  5.23it/s, loss=1.59, v_num=0, val_loss=1.640, val_acc_epoch=0.227, train_loss_step=1.310, train_loss_epoch=1.560, train_acc_epoch=0.255]\n","Epoch 3:  67% 8/12 [00:01<00:00,  4.97it/s, loss=1.55, v_num=0, val_loss=1.640, val_acc_epoch=0.227, train_loss_step=1.410, train_loss_epoch=1.560, train_acc_epoch=0.255]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 3:  83% 10/12 [00:01<00:00,  5.30it/s, loss=1.55, v_num=0, val_loss=1.640, val_acc_epoch=0.227, train_loss_step=1.410, train_loss_epoch=1.560, train_acc_epoch=0.255]\n","Epoch 3: 100% 12/12 [00:02<00:00,  5.86it/s, loss=1.55, v_num=0, val_loss=1.640, val_acc_epoch=0.227, train_loss_step=1.410, train_loss_epoch=1.560, train_acc_epoch=0.255]\n","Epoch 3: 100% 12/12 [00:02<00:00,  5.61it/s, loss=1.55, v_num=0, val_loss=1.630, val_acc_epoch=0.260, train_loss_step=1.570, train_loss_epoch=1.550, train_acc_epoch=0.270]\n","Epoch 4:  67% 8/12 [00:01<00:00,  4.53it/s, loss=1.53, v_num=0, val_loss=1.630, val_acc_epoch=0.260, train_loss_step=1.390, train_loss_epoch=1.550, train_acc_epoch=0.270]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 4:  83% 10/12 [00:02<00:00,  4.94it/s, loss=1.53, v_num=0, val_loss=1.630, val_acc_epoch=0.260, train_loss_step=1.390, train_loss_epoch=1.550, train_acc_epoch=0.270]\n","Epoch 4: 100% 12/12 [00:02<00:00,  5.49it/s, loss=1.53, v_num=0, val_loss=1.630, val_acc_epoch=0.260, train_loss_step=1.390, train_loss_epoch=1.550, train_acc_epoch=0.270]\n","Epoch 4: 100% 12/12 [00:02<00:00,  5.19it/s, loss=1.53, v_num=0, val_loss=1.630, val_acc_epoch=0.253, train_loss_step=1.370, train_loss_epoch=1.550, train_acc_epoch=0.275]\n","Epoch 5:  67% 8/12 [00:01<00:00,  4.65it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.253, train_loss_step=1.430, train_loss_epoch=1.550, train_acc_epoch=0.275]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.94it/s]\u001b[A\n","Epoch 5:  83% 10/12 [00:02<00:00,  4.73it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.253, train_loss_step=1.430, train_loss_epoch=1.550, train_acc_epoch=0.275]\n","Validating:  60% 3/5 [00:00<00:00,  6.33it/s]\u001b[A\n","Epoch 5: 100% 12/12 [00:02<00:00,  4.70it/s, loss=1.52, v_num=0, val_loss=1.620, val_acc_epoch=0.247, train_loss_step=1.280, train_loss_epoch=1.530, train_acc_epoch=0.330]\n","Epoch 6:  67% 8/12 [00:02<00:01,  3.34it/s, loss=1.5, v_num=0, val_loss=1.620, val_acc_epoch=0.247, train_loss_step=1.420, train_loss_epoch=1.530, train_acc_epoch=0.330]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.39it/s]\u001b[A\n","Epoch 6:  83% 10/12 [00:02<00:00,  3.50it/s, loss=1.5, v_num=0, val_loss=1.620, val_acc_epoch=0.247, train_loss_step=1.420, train_loss_epoch=1.530, train_acc_epoch=0.330]\n","Validating:  60% 3/5 [00:00<00:00,  5.80it/s]\u001b[A\n","Epoch 6: 100% 12/12 [00:03<00:00,  3.88it/s, loss=1.5, v_num=0, val_loss=1.620, val_acc_epoch=0.247, train_loss_step=1.420, train_loss_epoch=1.530, train_acc_epoch=0.330]\n","Epoch 6: 100% 12/12 [00:03<00:00,  3.67it/s, loss=1.5, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.250, train_loss_epoch=1.530, train_acc_epoch=0.285]\n","Epoch 7:  67% 8/12 [00:02<00:01,  3.50it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.420, train_loss_epoch=1.530, train_acc_epoch=0.285]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 7:  83% 10/12 [00:02<00:00,  3.86it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.420, train_loss_epoch=1.530, train_acc_epoch=0.285]\n","Epoch 7: 100% 12/12 [00:02<00:00,  4.30it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.420, train_loss_epoch=1.530, train_acc_epoch=0.285]\n","Epoch 7: 100% 12/12 [00:02<00:00,  4.12it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.430, train_loss_epoch=1.570, train_acc_epoch=0.275]\n","Epoch 8:  67% 8/12 [00:01<00:00,  4.20it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.440, train_loss_epoch=1.570, train_acc_epoch=0.275]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.86it/s]\u001b[A\n","Epoch 8:  83% 10/12 [00:02<00:00,  4.50it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.440, train_loss_epoch=1.570, train_acc_epoch=0.275]\n","Epoch 8: 100% 12/12 [00:02<00:00,  4.75it/s, loss=1.52, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.260, train_loss_epoch=1.550, train_acc_epoch=0.300]\n","Epoch 9:  67% 8/12 [00:01<00:00,  4.78it/s, loss=1.51, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.330, train_loss_epoch=1.550, train_acc_epoch=0.300]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.32it/s]\u001b[A\n","Epoch 9:  83% 10/12 [00:01<00:00,  5.05it/s, loss=1.51, v_num=0, val_loss=1.630, val_acc_epoch=0.240, train_loss_step=1.330, train_loss_epoch=1.550, train_acc_epoch=0.300]\n","Epoch 9: 100% 12/12 [00:02<00:00,  5.29it/s, loss=1.51, v_num=0, val_loss=1.630, val_acc_epoch=0.233, train_loss_step=1.290, train_loss_epoch=1.510, train_acc_epoch=0.335]\n","Epoch 10:  67% 8/12 [00:01<00:00,  4.25it/s, loss=1.5, v_num=0, val_loss=1.630, val_acc_epoch=0.233, train_loss_step=1.400, train_loss_epoch=1.510, train_acc_epoch=0.335]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.97it/s]\u001b[A\n","Epoch 10:  83% 10/12 [00:02<00:00,  4.56it/s, loss=1.5, v_num=0, val_loss=1.630, val_acc_epoch=0.233, train_loss_step=1.400, train_loss_epoch=1.510, train_acc_epoch=0.335]\n","Epoch 10: 100% 12/12 [00:02<00:00,  4.83it/s, loss=1.5, v_num=0, val_loss=1.620, val_acc_epoch=0.233, train_loss_step=1.460, train_loss_epoch=1.510, train_acc_epoch=0.295]\n","Epoch 11:  67% 8/12 [00:02<00:01,  3.91it/s, loss=1.48, v_num=0, val_loss=1.620, val_acc_epoch=0.233, train_loss_step=1.360, train_loss_epoch=1.510, train_acc_epoch=0.295]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.44it/s]\u001b[A\n","Epoch 11:  83% 10/12 [00:02<00:00,  4.05it/s, loss=1.48, v_num=0, val_loss=1.620, val_acc_epoch=0.233, train_loss_step=1.360, train_loss_epoch=1.510, train_acc_epoch=0.295]\n","Validating:  60% 3/5 [00:00<00:00,  6.13it/s]\u001b[A\n","Epoch 11: 100% 12/12 [00:02<00:00,  4.42it/s, loss=1.48, v_num=0, val_loss=1.620, val_acc_epoch=0.233, train_loss_step=1.360, train_loss_epoch=1.510, train_acc_epoch=0.295]\n","Epoch 11: 100% 12/12 [00:02<00:00,  4.12it/s, loss=1.48, v_num=0, val_loss=1.630, val_acc_epoch=0.247, train_loss_step=1.220, train_loss_epoch=1.490, train_acc_epoch=0.320]\n","Epoch 12:  67% 8/12 [00:02<00:01,  3.33it/s, loss=1.48, v_num=0, val_loss=1.630, val_acc_epoch=0.247, train_loss_step=1.410, train_loss_epoch=1.490, train_acc_epoch=0.320]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.88it/s]\u001b[A\n","Epoch 12:  83% 10/12 [00:02<00:00,  3.59it/s, loss=1.48, v_num=0, val_loss=1.630, val_acc_epoch=0.247, train_loss_step=1.410, train_loss_epoch=1.490, train_acc_epoch=0.320]\n","Validating:  60% 3/5 [00:00<00:00,  6.68it/s]\u001b[A\n","Epoch 12: 100% 12/12 [00:03<00:00,  3.78it/s, loss=1.48, v_num=0, val_loss=1.630, val_acc_epoch=0.227, train_loss_step=1.360, train_loss_epoch=1.520, train_acc_epoch=0.310]\n","Epoch 13:  67% 8/12 [00:02<00:01,  4.00it/s, loss=1.49, v_num=0, val_loss=1.630, val_acc_epoch=0.227, train_loss_step=1.430, train_loss_epoch=1.520, train_acc_epoch=0.310]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 13:  83% 10/12 [00:02<00:00,  4.41it/s, loss=1.49, v_num=0, val_loss=1.630, val_acc_epoch=0.227, train_loss_step=1.430, train_loss_epoch=1.520, train_acc_epoch=0.310]\n","Epoch 13: 100% 12/12 [00:02<00:00,  4.96it/s, loss=1.49, v_num=0, val_loss=1.630, val_acc_epoch=0.227, train_loss_step=1.430, train_loss_epoch=1.520, train_acc_epoch=0.310]\n","Epoch 13: 100% 12/12 [00:02<00:00,  4.77it/s, loss=1.49, v_num=0, val_loss=1.620, val_acc_epoch=0.227, train_loss_step=1.480, train_loss_epoch=1.510, train_acc_epoch=0.320]\n","Epoch 14:  67% 8/12 [00:01<00:00,  4.15it/s, loss=1.48, v_num=0, val_loss=1.620, val_acc_epoch=0.227, train_loss_step=1.440, train_loss_epoch=1.510, train_acc_epoch=0.320]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.36it/s]\u001b[A\n","Epoch 14:  83% 10/12 [00:02<00:00,  4.24it/s, loss=1.48, v_num=0, val_loss=1.620, val_acc_epoch=0.227, train_loss_step=1.440, train_loss_epoch=1.510, train_acc_epoch=0.320]\n","Validating:  60% 3/5 [00:00<00:00,  6.03it/s]\u001b[A\n","Epoch 14: 100% 12/12 [00:02<00:00,  4.59it/s, loss=1.48, v_num=0, val_loss=1.620, val_acc_epoch=0.227, train_loss_step=1.440, train_loss_epoch=1.510, train_acc_epoch=0.320]\n","Epoch 14: 100% 12/12 [00:02<00:00,  4.32it/s, loss=1.48, v_num=0, val_loss=1.610, val_acc_epoch=0.253, train_loss_step=1.270, train_loss_epoch=1.490, train_acc_epoch=0.280]\n","Epoch 15:  67% 8/12 [00:02<00:01,  3.12it/s, loss=1.47, v_num=0, val_loss=1.610, val_acc_epoch=0.253, train_loss_step=1.300, train_loss_epoch=1.490, train_acc_epoch=0.280]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.47it/s]\u001b[A\n","Epoch 15:  83% 10/12 [00:02<00:00,  3.36it/s, loss=1.47, v_num=0, val_loss=1.610, val_acc_epoch=0.253, train_loss_step=1.300, train_loss_epoch=1.490, train_acc_epoch=0.280]\n","Validating:  60% 3/5 [00:00<00:00,  6.40it/s]\u001b[A\n","Epoch 15: 100% 12/12 [00:03<00:00,  3.57it/s, loss=1.47, v_num=0, val_loss=1.610, val_acc_epoch=0.267, train_loss_step=1.400, train_loss_epoch=1.490, train_acc_epoch=0.305]\n","Epoch 16:  67% 8/12 [00:01<00:00,  4.31it/s, loss=1.47, v_num=0, val_loss=1.610, val_acc_epoch=0.267, train_loss_step=1.460, train_loss_epoch=1.490, train_acc_epoch=0.305]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.39it/s]\u001b[A\n","Epoch 16:  83% 10/12 [00:02<00:00,  4.38it/s, loss=1.47, v_num=0, val_loss=1.610, val_acc_epoch=0.267, train_loss_step=1.460, train_loss_epoch=1.490, train_acc_epoch=0.305]\n","Validating:  60% 3/5 [00:00<00:00,  6.14it/s]\u001b[A\n","Epoch 16: 100% 12/12 [00:02<00:00,  4.71it/s, loss=1.47, v_num=0, val_loss=1.610, val_acc_epoch=0.267, train_loss_step=1.460, train_loss_epoch=1.490, train_acc_epoch=0.305]\n","Epoch 16: 100% 12/12 [00:02<00:00,  4.39it/s, loss=1.47, v_num=0, val_loss=1.600, val_acc_epoch=0.273, train_loss_step=1.290, train_loss_epoch=1.510, train_acc_epoch=0.300]\n","Epoch 17:  67% 8/12 [00:02<00:01,  3.41it/s, loss=1.46, v_num=0, val_loss=1.600, val_acc_epoch=0.273, train_loss_step=1.420, train_loss_epoch=1.510, train_acc_epoch=0.300]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.99it/s]\u001b[A\n","Epoch 17:  83% 10/12 [00:02<00:00,  3.69it/s, loss=1.46, v_num=0, val_loss=1.600, val_acc_epoch=0.273, train_loss_step=1.420, train_loss_epoch=1.510, train_acc_epoch=0.300]\n","Validating:  60% 3/5 [00:00<00:00,  7.10it/s]\u001b[A\n","Epoch 17: 100% 12/12 [00:03<00:00,  3.89it/s, loss=1.46, v_num=0, val_loss=1.600, val_acc_epoch=0.260, train_loss_step=1.100, train_loss_epoch=1.470, train_acc_epoch=0.340]\n","Epoch 18:  67% 8/12 [00:02<00:01,  3.87it/s, loss=1.44, v_num=0, val_loss=1.600, val_acc_epoch=0.260, train_loss_step=1.390, train_loss_epoch=1.470, train_acc_epoch=0.340]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 18:  83% 10/12 [00:02<00:00,  4.31it/s, loss=1.44, v_num=0, val_loss=1.600, val_acc_epoch=0.260, train_loss_step=1.390, train_loss_epoch=1.470, train_acc_epoch=0.340]\n","Epoch 18: 100% 12/12 [00:02<00:00,  4.86it/s, loss=1.44, v_num=0, val_loss=1.600, val_acc_epoch=0.260, train_loss_step=1.390, train_loss_epoch=1.470, train_acc_epoch=0.340]\n","Epoch 18: 100% 12/12 [00:02<00:00,  4.68it/s, loss=1.44, v_num=0, val_loss=1.590, val_acc_epoch=0.253, train_loss_step=1.210, train_loss_epoch=1.470, train_acc_epoch=0.305]\n","Epoch 19:  67% 8/12 [00:01<00:00,  4.57it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.253, train_loss_step=1.410, train_loss_epoch=1.470, train_acc_epoch=0.305]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 19:  83% 10/12 [00:02<00:00,  4.98it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.253, train_loss_step=1.410, train_loss_epoch=1.470, train_acc_epoch=0.305]\n","Epoch 19: 100% 12/12 [00:02<00:00,  5.49it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.253, train_loss_step=1.410, train_loss_epoch=1.470, train_acc_epoch=0.305]\n","Epoch 19: 100% 12/12 [00:02<00:00,  5.18it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.310, train_loss_epoch=1.460, train_acc_epoch=0.305]\n","Epoch 20:  67% 8/12 [00:01<00:00,  4.94it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.360, train_loss_epoch=1.460, train_acc_epoch=0.305]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.29it/s]\u001b[A\n","Epoch 20:  83% 10/12 [00:01<00:00,  5.17it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.360, train_loss_epoch=1.460, train_acc_epoch=0.305]\n","Epoch 20: 100% 12/12 [00:02<00:00,  5.38it/s, loss=1.43, v_num=0, val_loss=1.600, val_acc_epoch=0.267, train_loss_step=1.230, train_loss_epoch=1.460, train_acc_epoch=0.375]\n","Epoch 21:  67% 8/12 [00:01<00:00,  4.32it/s, loss=1.43, v_num=0, val_loss=1.600, val_acc_epoch=0.267, train_loss_step=1.340, train_loss_epoch=1.460, train_acc_epoch=0.375]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 21:  83% 10/12 [00:02<00:00,  4.63it/s, loss=1.43, v_num=0, val_loss=1.600, val_acc_epoch=0.267, train_loss_step=1.340, train_loss_epoch=1.460, train_acc_epoch=0.375]\n","Epoch 21: 100% 12/12 [00:02<00:00,  5.10it/s, loss=1.43, v_num=0, val_loss=1.600, val_acc_epoch=0.267, train_loss_step=1.340, train_loss_epoch=1.460, train_acc_epoch=0.375]\n","Epoch 21: 100% 12/12 [00:02<00:00,  4.86it/s, loss=1.43, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.330, train_loss_epoch=1.430, train_acc_epoch=0.420]\n","Epoch 22:  67% 8/12 [00:01<00:00,  4.32it/s, loss=1.42, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.300, train_loss_epoch=1.430, train_acc_epoch=0.420]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.75it/s]\u001b[A\n","Epoch 22:  83% 10/12 [00:02<00:00,  4.41it/s, loss=1.42, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.300, train_loss_epoch=1.430, train_acc_epoch=0.420]\n","Validating:  60% 3/5 [00:00<00:00,  5.85it/s]\u001b[A\n","Epoch 22: 100% 12/12 [00:02<00:00,  4.75it/s, loss=1.42, v_num=0, val_loss=1.590, val_acc_epoch=0.287, train_loss_step=1.300, train_loss_epoch=1.430, train_acc_epoch=0.420]\n","Epoch 22: 100% 12/12 [00:02<00:00,  4.41it/s, loss=1.42, v_num=0, val_loss=1.580, val_acc_epoch=0.313, train_loss_step=1.450, train_loss_epoch=1.440, train_acc_epoch=0.375]\n","Epoch 23:  67% 8/12 [00:02<00:01,  3.41it/s, loss=1.42, v_num=0, val_loss=1.580, val_acc_epoch=0.313, train_loss_step=1.250, train_loss_epoch=1.440, train_acc_epoch=0.375]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.06it/s]\u001b[A\n","Epoch 23:  83% 10/12 [00:02<00:00,  3.67it/s, loss=1.42, v_num=0, val_loss=1.580, val_acc_epoch=0.313, train_loss_step=1.250, train_loss_epoch=1.440, train_acc_epoch=0.375]\n","Validating:  60% 3/5 [00:00<00:00,  6.87it/s]\u001b[A\n","Epoch 23: 100% 12/12 [00:02<00:00,  4.07it/s, loss=1.42, v_num=0, val_loss=1.580, val_acc_epoch=0.313, train_loss_step=1.250, train_loss_epoch=1.440, train_acc_epoch=0.375]\n","Epoch 23: 100% 12/12 [00:03<00:00,  3.87it/s, loss=1.42, v_num=0, val_loss=1.570, val_acc_epoch=0.293, train_loss_step=1.460, train_loss_epoch=1.400, train_acc_epoch=0.450]\n","Epoch 24:  67% 8/12 [00:01<00:00,  4.04it/s, loss=1.41, v_num=0, val_loss=1.570, val_acc_epoch=0.293, train_loss_step=1.260, train_loss_epoch=1.400, train_acc_epoch=0.450]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  6.11it/s]\u001b[A\n","Epoch 24:  83% 10/12 [00:02<00:00,  4.45it/s, loss=1.41, v_num=0, val_loss=1.570, val_acc_epoch=0.293, train_loss_step=1.260, train_loss_epoch=1.400, train_acc_epoch=0.450]\n","Epoch 24: 100% 12/12 [00:02<00:00,  4.74it/s, loss=1.41, v_num=0, val_loss=1.570, val_acc_epoch=0.307, train_loss_step=1.330, train_loss_epoch=1.430, train_acc_epoch=0.395]\n","Epoch 25:  67% 8/12 [00:01<00:00,  4.46it/s, loss=1.4, v_num=0, val_loss=1.570, val_acc_epoch=0.307, train_loss_step=1.300, train_loss_epoch=1.430, train_acc_epoch=0.395]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  6.11it/s]\u001b[A\n","Epoch 25:  83% 10/12 [00:02<00:00,  4.85it/s, loss=1.4, v_num=0, val_loss=1.570, val_acc_epoch=0.307, train_loss_step=1.300, train_loss_epoch=1.430, train_acc_epoch=0.395]\n","Epoch 25: 100% 12/12 [00:02<00:00,  5.20it/s, loss=1.4, v_num=0, val_loss=1.550, val_acc_epoch=0.300, train_loss_step=1.240, train_loss_epoch=1.420, train_acc_epoch=0.355]\n","Epoch 26:  67% 8/12 [00:01<00:00,  4.97it/s, loss=1.41, v_num=0, val_loss=1.550, val_acc_epoch=0.300, train_loss_step=1.320, train_loss_epoch=1.420, train_acc_epoch=0.355]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.57it/s]\u001b[A\n","Epoch 26:  83% 10/12 [00:01<00:00,  5.18it/s, loss=1.41, v_num=0, val_loss=1.550, val_acc_epoch=0.300, train_loss_step=1.320, train_loss_epoch=1.420, train_acc_epoch=0.355]\n","Epoch 26: 100% 12/12 [00:02<00:00,  5.34it/s, loss=1.41, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.350, train_loss_epoch=1.410, train_acc_epoch=0.385]\n","Epoch 27:  67% 8/12 [00:01<00:00,  4.39it/s, loss=1.38, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.220, train_loss_epoch=1.410, train_acc_epoch=0.385]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 27:  83% 10/12 [00:02<00:00,  4.71it/s, loss=1.38, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.220, train_loss_epoch=1.410, train_acc_epoch=0.385]\n","Epoch 27: 100% 12/12 [00:02<00:00,  5.28it/s, loss=1.38, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.220, train_loss_epoch=1.410, train_acc_epoch=0.385]\n","Epoch 27: 100% 12/12 [00:02<00:00,  5.06it/s, loss=1.38, v_num=0, val_loss=1.520, val_acc_epoch=0.300, train_loss_step=1.320, train_loss_epoch=1.390, train_acc_epoch=0.425]\n","Epoch 28:  67% 8/12 [00:01<00:00,  4.75it/s, loss=1.38, v_num=0, val_loss=1.520, val_acc_epoch=0.300, train_loss_step=1.310, train_loss_epoch=1.390, train_acc_epoch=0.425]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.52it/s]\u001b[A\n","Epoch 28:  83% 10/12 [00:02<00:00,  4.75it/s, loss=1.38, v_num=0, val_loss=1.520, val_acc_epoch=0.300, train_loss_step=1.310, train_loss_epoch=1.390, train_acc_epoch=0.425]\n","Validating:  60% 3/5 [00:00<00:00,  5.96it/s]\u001b[A\n","Epoch 28: 100% 12/12 [00:02<00:00,  5.08it/s, loss=1.38, v_num=0, val_loss=1.520, val_acc_epoch=0.300, train_loss_step=1.310, train_loss_epoch=1.390, train_acc_epoch=0.425]\n","Epoch 28: 100% 12/12 [00:02<00:00,  4.72it/s, loss=1.38, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.250, train_loss_epoch=1.370, train_acc_epoch=0.415]\n","Epoch 29:  67% 8/12 [00:02<00:01,  3.53it/s, loss=1.37, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.240, train_loss_epoch=1.370, train_acc_epoch=0.415]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.87it/s]\u001b[A\n","Epoch 29:  83% 10/12 [00:02<00:00,  3.77it/s, loss=1.37, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.240, train_loss_epoch=1.370, train_acc_epoch=0.415]\n","Validating:  60% 3/5 [00:00<00:00,  6.72it/s]\u001b[A\n","Epoch 29: 100% 12/12 [00:03<00:00,  3.98it/s, loss=1.37, v_num=0, val_loss=1.550, val_acc_epoch=0.313, train_loss_step=1.320, train_loss_epoch=1.370, train_acc_epoch=0.410]\n","Epoch 30:  67% 8/12 [00:02<00:01,  3.50it/s, loss=1.36, v_num=0, val_loss=1.550, val_acc_epoch=0.313, train_loss_step=1.200, train_loss_epoch=1.370, train_acc_epoch=0.410]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.59it/s]\u001b[A\n","Epoch 30:  83% 10/12 [00:02<00:00,  3.89it/s, loss=1.36, v_num=0, val_loss=1.550, val_acc_epoch=0.313, train_loss_step=1.200, train_loss_epoch=1.370, train_acc_epoch=0.410]\n","Epoch 30: 100% 12/12 [00:02<00:00,  4.25it/s, loss=1.36, v_num=0, val_loss=1.550, val_acc_epoch=0.307, train_loss_step=1.230, train_loss_epoch=1.360, train_acc_epoch=0.410]\n","Epoch 31:  67% 8/12 [00:01<00:00,  4.56it/s, loss=1.33, v_num=0, val_loss=1.550, val_acc_epoch=0.307, train_loss_step=1.240, train_loss_epoch=1.360, train_acc_epoch=0.410]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.56it/s]\u001b[A\n","Epoch 31:  83% 10/12 [00:02<00:00,  4.80it/s, loss=1.33, v_num=0, val_loss=1.550, val_acc_epoch=0.307, train_loss_step=1.240, train_loss_epoch=1.360, train_acc_epoch=0.410]\n","Epoch 31: 100% 12/12 [00:02<00:00,  5.04it/s, loss=1.33, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.040, train_loss_epoch=1.340, train_acc_epoch=0.435]\n","Epoch 32:  67% 8/12 [00:01<00:00,  4.58it/s, loss=1.31, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.210, train_loss_epoch=1.340, train_acc_epoch=0.435]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 32:  83% 10/12 [00:02<00:00,  4.96it/s, loss=1.31, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.210, train_loss_epoch=1.340, train_acc_epoch=0.435]\n","Epoch 32: 100% 12/12 [00:02<00:00,  5.51it/s, loss=1.31, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.210, train_loss_epoch=1.340, train_acc_epoch=0.435]\n","Epoch 32: 100% 12/12 [00:02<00:00,  5.23it/s, loss=1.31, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.240, train_loss_epoch=1.320, train_acc_epoch=0.425]\n","Epoch 33:  67% 8/12 [00:01<00:00,  4.66it/s, loss=1.31, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.220, train_loss_epoch=1.320, train_acc_epoch=0.425]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 33:  83% 10/12 [00:01<00:00,  5.01it/s, loss=1.31, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.220, train_loss_epoch=1.320, train_acc_epoch=0.425]\n","Epoch 33: 100% 12/12 [00:02<00:00,  5.53it/s, loss=1.31, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.220, train_loss_epoch=1.320, train_acc_epoch=0.425]\n","Epoch 33: 100% 12/12 [00:02<00:00,  5.25it/s, loss=1.31, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.130, train_loss_epoch=1.330, train_acc_epoch=0.395]\n","Epoch 34:  67% 8/12 [00:01<00:00,  4.13it/s, loss=1.29, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.220, train_loss_epoch=1.330, train_acc_epoch=0.395]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.92it/s]\u001b[A\n","Epoch 34:  83% 10/12 [00:02<00:00,  4.31it/s, loss=1.29, v_num=0, val_loss=1.530, val_acc_epoch=0.300, train_loss_step=1.220, train_loss_epoch=1.330, train_acc_epoch=0.395]\n","Epoch 34: 100% 12/12 [00:02<00:00,  4.49it/s, loss=1.29, v_num=0, val_loss=1.550, val_acc_epoch=0.293, train_loss_step=0.974, train_loss_epoch=1.310, train_acc_epoch=0.420]\n","Epoch 35:  67% 8/12 [00:02<00:01,  3.77it/s, loss=1.29, v_num=0, val_loss=1.550, val_acc_epoch=0.293, train_loss_step=1.120, train_loss_epoch=1.310, train_acc_epoch=0.420]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.40it/s]\u001b[A\n","Epoch 35:  83% 10/12 [00:02<00:00,  3.88it/s, loss=1.29, v_num=0, val_loss=1.550, val_acc_epoch=0.293, train_loss_step=1.120, train_loss_epoch=1.310, train_acc_epoch=0.420]\n","Validating:  60% 3/5 [00:00<00:00,  5.82it/s]\u001b[A\n","Epoch 35: 100% 12/12 [00:03<00:00,  3.99it/s, loss=1.29, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.260, train_loss_epoch=1.290, train_acc_epoch=0.470]\n","Epoch 36:  67% 8/12 [00:01<00:00,  4.08it/s, loss=1.28, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.130, train_loss_epoch=1.290, train_acc_epoch=0.470]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.26it/s]\u001b[A\n","Epoch 36:  83% 10/12 [00:02<00:00,  4.43it/s, loss=1.28, v_num=0, val_loss=1.540, val_acc_epoch=0.300, train_loss_step=1.130, train_loss_epoch=1.290, train_acc_epoch=0.470]\n","Epoch 36: 100% 12/12 [00:02<00:00,  4.73it/s, loss=1.28, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=0.988, train_loss_epoch=1.300, train_acc_epoch=0.475]\n","Epoch 37:  67% 8/12 [00:01<00:00,  4.82it/s, loss=1.27, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.400, train_loss_epoch=1.300, train_acc_epoch=0.475]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.96it/s]\u001b[A\n","Epoch 37:  83% 10/12 [00:01<00:00,  5.06it/s, loss=1.27, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.400, train_loss_epoch=1.300, train_acc_epoch=0.475]\n","Epoch 37: 100% 12/12 [00:02<00:00,  5.26it/s, loss=1.27, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.040, train_loss_epoch=1.320, train_acc_epoch=0.415]\n","Epoch 38:  67% 8/12 [00:01<00:00,  4.84it/s, loss=1.27, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.320, train_loss_epoch=1.320, train_acc_epoch=0.415]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.93it/s]\u001b[A\n","Epoch 38:  83% 10/12 [00:01<00:00,  5.09it/s, loss=1.27, v_num=0, val_loss=1.520, val_acc_epoch=0.293, train_loss_step=1.320, train_loss_epoch=1.320, train_acc_epoch=0.415]\n","Epoch 38: 100% 12/12 [00:02<00:00,  5.34it/s, loss=1.27, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.220, train_loss_epoch=1.270, train_acc_epoch=0.480]\n","Epoch 39:  67% 8/12 [00:01<00:00,  4.32it/s, loss=1.27, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.160, train_loss_epoch=1.270, train_acc_epoch=0.480]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 39:  83% 10/12 [00:02<00:00,  4.65it/s, loss=1.27, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.160, train_loss_epoch=1.270, train_acc_epoch=0.480]\n","Epoch 39: 100% 12/12 [00:02<00:00,  5.14it/s, loss=1.27, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.160, train_loss_epoch=1.270, train_acc_epoch=0.480]\n","Epoch 39: 100% 12/12 [00:02<00:00,  4.91it/s, loss=1.27, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.120, train_loss_epoch=1.290, train_acc_epoch=0.430]\n","Epoch 40:  67% 8/12 [00:01<00:00,  4.86it/s, loss=1.25, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.210, train_loss_epoch=1.290, train_acc_epoch=0.430]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.40it/s]\u001b[A\n","Epoch 40:  83% 10/12 [00:02<00:00,  4.98it/s, loss=1.25, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.210, train_loss_epoch=1.290, train_acc_epoch=0.430]\n","Validating:  60% 3/5 [00:00<00:00,  6.62it/s]\u001b[A\n","Epoch 40: 100% 12/12 [00:02<00:00,  5.30it/s, loss=1.25, v_num=0, val_loss=1.530, val_acc_epoch=0.307, train_loss_step=1.210, train_loss_epoch=1.290, train_acc_epoch=0.430]\n","Epoch 40: 100% 12/12 [00:02<00:00,  4.92it/s, loss=1.25, v_num=0, val_loss=1.540, val_acc_epoch=0.333, train_loss_step=1.030, train_loss_epoch=1.260, train_acc_epoch=0.405]\n","Epoch 41:  67% 8/12 [00:02<00:01,  3.09it/s, loss=1.25, v_num=0, val_loss=1.540, val_acc_epoch=0.333, train_loss_step=1.190, train_loss_epoch=1.260, train_acc_epoch=0.405]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.46it/s]\u001b[A\n","Epoch 41:  83% 10/12 [00:03<00:00,  3.32it/s, loss=1.25, v_num=0, val_loss=1.540, val_acc_epoch=0.333, train_loss_step=1.190, train_loss_epoch=1.260, train_acc_epoch=0.405]\n","Validating:  60% 3/5 [00:00<00:00,  5.71it/s]\u001b[A\n","Epoch 41: 100% 12/12 [00:03<00:00,  3.65it/s, loss=1.25, v_num=0, val_loss=1.540, val_acc_epoch=0.333, train_loss_step=1.190, train_loss_epoch=1.260, train_acc_epoch=0.405]\n","Epoch 41: 100% 12/12 [00:03<00:00,  3.47it/s, loss=1.25, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.230, train_loss_epoch=1.280, train_acc_epoch=0.470]\n","Epoch 42:  67% 8/12 [00:02<00:01,  3.53it/s, loss=1.25, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.120, train_loss_epoch=1.280, train_acc_epoch=0.470]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 42:  83% 10/12 [00:02<00:00,  3.89it/s, loss=1.25, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.120, train_loss_epoch=1.280, train_acc_epoch=0.470]\n","Validating:  60% 3/5 [00:00<00:00,  8.19it/s]\u001b[A\n","Epoch 42: 100% 12/12 [00:02<00:00,  4.16it/s, loss=1.25, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.410, train_loss_epoch=1.230, train_acc_epoch=0.475]\n","Epoch 43:  67% 8/12 [00:01<00:00,  5.19it/s, loss=1.26, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.220, train_loss_epoch=1.230, train_acc_epoch=0.475]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 43:  83% 10/12 [00:01<00:00,  5.53it/s, loss=1.26, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.220, train_loss_epoch=1.230, train_acc_epoch=0.475]\n","Epoch 43: 100% 12/12 [00:01<00:00,  6.06it/s, loss=1.26, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.220, train_loss_epoch=1.230, train_acc_epoch=0.475]\n","Epoch 43: 100% 12/12 [00:02<00:00,  5.69it/s, loss=1.26, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.230, train_loss_epoch=1.250, train_acc_epoch=0.505]\n","Epoch 44:  67% 8/12 [00:01<00:00,  4.67it/s, loss=1.24, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.040, train_loss_epoch=1.250, train_acc_epoch=0.505]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 44:  83% 10/12 [00:01<00:00,  5.02it/s, loss=1.24, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.040, train_loss_epoch=1.250, train_acc_epoch=0.505]\n","Epoch 44: 100% 12/12 [00:02<00:00,  5.62it/s, loss=1.24, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.040, train_loss_epoch=1.250, train_acc_epoch=0.505]\n","Epoch 44: 100% 12/12 [00:02<00:00,  5.36it/s, loss=1.24, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.310, train_loss_epoch=1.230, train_acc_epoch=0.490]\n","Epoch 45:  67% 8/12 [00:01<00:00,  4.61it/s, loss=1.22, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.150, train_loss_epoch=1.230, train_acc_epoch=0.490]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 45:  83% 10/12 [00:01<00:00,  5.02it/s, loss=1.22, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.150, train_loss_epoch=1.230, train_acc_epoch=0.490]\n","Epoch 45: 100% 12/12 [00:02<00:00,  5.60it/s, loss=1.22, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.150, train_loss_epoch=1.230, train_acc_epoch=0.490]\n","Epoch 45: 100% 12/12 [00:02<00:00,  5.35it/s, loss=1.22, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.110, train_loss_epoch=1.210, train_acc_epoch=0.525]\n","Epoch 46:  67% 8/12 [00:01<00:00,  4.37it/s, loss=1.23, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.140, train_loss_epoch=1.210, train_acc_epoch=0.525]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.03it/s]\u001b[A\n","Epoch 46:  83% 10/12 [00:02<00:00,  4.53it/s, loss=1.23, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.140, train_loss_epoch=1.210, train_acc_epoch=0.525]\n","Validating:  60% 3/5 [00:00<00:00,  6.58it/s]\u001b[A\n","Epoch 46: 100% 12/12 [00:02<00:00,  4.65it/s, loss=1.23, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.410, train_loss_epoch=1.260, train_acc_epoch=0.445]\n","Epoch 47:  67% 8/12 [00:02<00:01,  3.27it/s, loss=1.21, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.240, train_loss_epoch=1.260, train_acc_epoch=0.445]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.49it/s]\u001b[A\n","Epoch 47:  83% 10/12 [00:02<00:00,  3.49it/s, loss=1.21, v_num=0, val_loss=1.520, val_acc_epoch=0.320, train_loss_step=1.240, train_loss_epoch=1.260, train_acc_epoch=0.445]\n","Validating:  60% 3/5 [00:00<00:00,  5.76it/s]\u001b[A\n","Epoch 47: 100% 12/12 [00:03<00:00,  3.62it/s, loss=1.21, v_num=0, val_loss=1.500, val_acc_epoch=0.320, train_loss_step=1.040, train_loss_epoch=1.200, train_acc_epoch=0.540]\n","Epoch 48:  67% 8/12 [00:02<00:01,  3.37it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.320, train_loss_step=1.070, train_loss_epoch=1.200, train_acc_epoch=0.540]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 48:  83% 10/12 [00:02<00:00,  3.75it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.320, train_loss_step=1.070, train_loss_epoch=1.200, train_acc_epoch=0.540]\n","Epoch 48: 100% 12/12 [00:02<00:00,  4.24it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.320, train_loss_step=1.070, train_loss_epoch=1.200, train_acc_epoch=0.540]\n","Epoch 48: 100% 12/12 [00:02<00:00,  4.10it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=0.966, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Epoch 49:  67% 8/12 [00:01<00:00,  4.57it/s, loss=1.16, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.130, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.75it/s]\u001b[A\n","Epoch 49:  83% 10/12 [00:02<00:00,  4.84it/s, loss=1.16, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.130, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Epoch 49: 100% 12/12 [00:02<00:00,  5.09it/s, loss=1.16, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.210, train_loss_epoch=1.160, train_acc_epoch=0.560]\n","Epoch 50:  67% 8/12 [00:01<00:00,  4.24it/s, loss=1.16, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.060, train_loss_epoch=1.160, train_acc_epoch=0.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.97it/s]\u001b[A\n","Epoch 50:  83% 10/12 [00:02<00:00,  4.55it/s, loss=1.16, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.060, train_loss_epoch=1.160, train_acc_epoch=0.560]\n","Epoch 50: 100% 12/12 [00:02<00:00,  4.84it/s, loss=1.16, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.340, train_loss_epoch=1.130, train_acc_epoch=0.535]\n","Epoch 51:  67% 8/12 [00:01<00:00,  4.54it/s, loss=1.17, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.150, train_loss_epoch=1.130, train_acc_epoch=0.535]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.86it/s]\u001b[A\n","Epoch 51:  83% 10/12 [00:02<00:00,  4.81it/s, loss=1.17, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.150, train_loss_epoch=1.130, train_acc_epoch=0.535]\n","Epoch 51: 100% 12/12 [00:02<00:00,  5.15it/s, loss=1.17, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.290, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Epoch 52:  67% 8/12 [00:01<00:00,  4.54it/s, loss=1.19, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.140, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.27it/s]\u001b[A\n","Epoch 52:  83% 10/12 [00:02<00:00,  4.52it/s, loss=1.19, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.140, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Validating:  60% 3/5 [00:00<00:00,  6.08it/s]\u001b[A\n","Epoch 52: 100% 12/12 [00:02<00:00,  4.92it/s, loss=1.19, v_num=0, val_loss=1.510, val_acc_epoch=0.313, train_loss_step=1.140, train_loss_epoch=1.170, train_acc_epoch=0.515]\n","Epoch 52: 100% 12/12 [00:02<00:00,  4.57it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.340, train_loss_step=1.440, train_loss_epoch=1.180, train_acc_epoch=0.515]\n","Epoch 53:  67% 8/12 [00:02<00:01,  3.10it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.340, train_loss_step=1.130, train_loss_epoch=1.180, train_acc_epoch=0.515]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.28it/s]\u001b[A\n","Epoch 53:  83% 10/12 [00:03<00:00,  3.31it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.340, train_loss_step=1.130, train_loss_epoch=1.180, train_acc_epoch=0.515]\n","Validating:  60% 3/5 [00:00<00:00,  6.06it/s]\u001b[A\n","Epoch 53: 100% 12/12 [00:03<00:00,  3.67it/s, loss=1.19, v_num=0, val_loss=1.500, val_acc_epoch=0.340, train_loss_step=1.130, train_loss_epoch=1.180, train_acc_epoch=0.515]\n","Epoch 53: 100% 12/12 [00:03<00:00,  3.46it/s, loss=1.19, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.160, train_loss_epoch=1.190, train_acc_epoch=0.500]\n","Epoch 54:  67% 8/12 [00:02<00:01,  3.85it/s, loss=1.19, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.110, train_loss_epoch=1.190, train_acc_epoch=0.500]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.55it/s]\u001b[A\n","Epoch 54:  83% 10/12 [00:02<00:00,  4.14it/s, loss=1.19, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.110, train_loss_epoch=1.190, train_acc_epoch=0.500]\n","Epoch 54: 100% 12/12 [00:02<00:00,  4.42it/s, loss=1.19, v_num=0, val_loss=1.550, val_acc_epoch=0.327, train_loss_step=1.160, train_loss_epoch=1.180, train_acc_epoch=0.535]\n","Epoch 55:  67% 8/12 [00:01<00:00,  4.90it/s, loss=1.17, v_num=0, val_loss=1.550, val_acc_epoch=0.327, train_loss_step=1.230, train_loss_epoch=1.180, train_acc_epoch=0.535]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 55:  83% 10/12 [00:01<00:00,  5.25it/s, loss=1.17, v_num=0, val_loss=1.550, val_acc_epoch=0.327, train_loss_step=1.230, train_loss_epoch=1.180, train_acc_epoch=0.535]\n","Epoch 55: 100% 12/12 [00:02<00:00,  5.85it/s, loss=1.17, v_num=0, val_loss=1.550, val_acc_epoch=0.327, train_loss_step=1.230, train_loss_epoch=1.180, train_acc_epoch=0.535]\n","Validating: 100% 5/5 [00:00<00:00, 11.28it/s]\u001b[AEpoch 00056: reducing learning rate of group 0 to 5.0000e-05.\n","Epoch 55: 100% 12/12 [00:02<00:00,  5.58it/s, loss=1.17, v_num=0, val_loss=1.510, val_acc_epoch=0.327, train_loss_step=1.190, train_loss_epoch=1.150, train_acc_epoch=0.545]\n","Epoch 56:  67% 8/12 [00:01<00:00,  4.48it/s, loss=1.16, v_num=0, val_loss=1.510, val_acc_epoch=0.327, train_loss_step=1.040, train_loss_epoch=1.150, train_acc_epoch=0.545]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.86it/s]\u001b[A\n","Epoch 56:  83% 10/12 [00:02<00:00,  4.76it/s, loss=1.16, v_num=0, val_loss=1.510, val_acc_epoch=0.327, train_loss_step=1.040, train_loss_epoch=1.150, train_acc_epoch=0.545]\n","Epoch 56: 100% 12/12 [00:02<00:00,  4.94it/s, loss=1.16, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.170, train_loss_epoch=1.150, train_acc_epoch=0.555]\n","Epoch 57:  67% 8/12 [00:01<00:00,  4.86it/s, loss=1.16, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.090, train_loss_epoch=1.150, train_acc_epoch=0.555]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  6.04it/s]\u001b[A\n","Epoch 57:  83% 10/12 [00:01<00:00,  5.22it/s, loss=1.16, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.090, train_loss_epoch=1.150, train_acc_epoch=0.555]\n","Epoch 57: 100% 12/12 [00:02<00:00,  5.57it/s, loss=1.16, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.100, train_loss_epoch=1.150, train_acc_epoch=0.560]\n","Epoch 58:  67% 8/12 [00:01<00:00,  4.57it/s, loss=1.13, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.110, train_loss_epoch=1.150, train_acc_epoch=0.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.47it/s]\u001b[A\n","Epoch 58:  83% 10/12 [00:02<00:00,  4.58it/s, loss=1.13, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.110, train_loss_epoch=1.150, train_acc_epoch=0.560]\n","Validating:  60% 3/5 [00:00<00:00,  6.04it/s]\u001b[A\n","Epoch 58: 100% 12/12 [00:02<00:00,  4.93it/s, loss=1.13, v_num=0, val_loss=1.500, val_acc_epoch=0.313, train_loss_step=1.110, train_loss_epoch=1.150, train_acc_epoch=0.560]\n","Epoch 58: 100% 12/12 [00:02<00:00,  4.59it/s, loss=1.13, v_num=0, val_loss=1.520, val_acc_epoch=0.307, train_loss_step=1.110, train_loss_epoch=1.120, train_acc_epoch=0.565]\n","Epoch 59:  67% 8/12 [00:02<00:01,  3.10it/s, loss=1.13, v_num=0, val_loss=1.520, val_acc_epoch=0.307, train_loss_step=0.883, train_loss_epoch=1.120, train_acc_epoch=0.565]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.45it/s]\u001b[A\n","Epoch 59:  83% 10/12 [00:03<00:00,  3.32it/s, loss=1.13, v_num=0, val_loss=1.520, val_acc_epoch=0.307, train_loss_step=0.883, train_loss_epoch=1.120, train_acc_epoch=0.565]\n","Validating:  60% 3/5 [00:00<00:00,  5.93it/s]\u001b[A\n","Epoch 59: 100% 12/12 [00:03<00:00,  3.68it/s, loss=1.13, v_num=0, val_loss=1.520, val_acc_epoch=0.307, train_loss_step=0.883, train_loss_epoch=1.120, train_acc_epoch=0.565]\n","Epoch 59: 100% 12/12 [00:03<00:00,  3.48it/s, loss=1.13, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.230, train_loss_epoch=1.140, train_acc_epoch=0.570]\n","Epoch 60:  67% 8/12 [00:02<00:01,  3.74it/s, loss=1.14, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.220, train_loss_epoch=1.140, train_acc_epoch=0.570]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 60:  83% 10/12 [00:02<00:00,  4.15it/s, loss=1.14, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.220, train_loss_epoch=1.140, train_acc_epoch=0.570]\n","Epoch 60: 100% 12/12 [00:02<00:00,  4.68it/s, loss=1.14, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.220, train_loss_epoch=1.140, train_acc_epoch=0.570]\n","Epoch 60: 100% 12/12 [00:02<00:00,  4.47it/s, loss=1.14, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=0.977, train_loss_epoch=1.160, train_acc_epoch=0.545]\n","Epoch 61:  67% 8/12 [00:01<00:00,  4.32it/s, loss=1.14, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.140, train_loss_epoch=1.160, train_acc_epoch=0.545]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.80it/s]\u001b[A\n","Epoch 61:  83% 10/12 [00:02<00:00,  4.59it/s, loss=1.14, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.140, train_loss_epoch=1.160, train_acc_epoch=0.545]\n","Epoch 61: 100% 12/12 [00:02<00:00,  4.84it/s, loss=1.14, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.120, train_loss_epoch=1.130, train_acc_epoch=0.545]\n","Epoch 62:  67% 8/12 [00:01<00:00,  4.91it/s, loss=1.12, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.010, train_loss_epoch=1.130, train_acc_epoch=0.545]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 62:  83% 10/12 [00:01<00:00,  5.27it/s, loss=1.12, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.010, train_loss_epoch=1.130, train_acc_epoch=0.545]\n","Epoch 62: 100% 12/12 [00:02<00:00,  5.84it/s, loss=1.12, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.010, train_loss_epoch=1.130, train_acc_epoch=0.545]\n","Epoch 62: 100% 12/12 [00:02<00:00,  5.53it/s, loss=1.12, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=1.020, train_loss_epoch=1.110, train_acc_epoch=0.560]\n","Epoch 63:  67% 8/12 [00:01<00:00,  5.00it/s, loss=1.12, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=0.978, train_loss_epoch=1.110, train_acc_epoch=0.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.98it/s]\u001b[A\n","Epoch 63:  83% 10/12 [00:01<00:00,  5.18it/s, loss=1.12, v_num=0, val_loss=1.510, val_acc_epoch=0.320, train_loss_step=0.978, train_loss_epoch=1.110, train_acc_epoch=0.560]\n","Epoch 63: 100% 12/12 [00:02<00:00,  5.32it/s, loss=1.12, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.210, train_loss_epoch=1.130, train_acc_epoch=0.525]\n","Epoch 64:  67% 8/12 [00:01<00:00,  5.02it/s, loss=1.1, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.100, train_loss_epoch=1.130, train_acc_epoch=0.525]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.35it/s]\u001b[A\n","Epoch 64:  83% 10/12 [00:01<00:00,  5.21it/s, loss=1.1, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.100, train_loss_epoch=1.130, train_acc_epoch=0.525]\n","Validating:  60% 3/5 [00:00<00:00,  7.49it/s]\u001b[A\n","Epoch 64: 100% 12/12 [00:02<00:00,  5.63it/s, loss=1.1, v_num=0, val_loss=1.520, val_acc_epoch=0.313, train_loss_step=1.100, train_loss_epoch=1.130, train_acc_epoch=0.525]\n","Epoch 64: 100% 12/12 [00:02<00:00,  5.19it/s, loss=1.1, v_num=0, val_loss=1.520, val_acc_epoch=0.327, train_loss_step=0.700, train_loss_epoch=1.100, train_acc_epoch=0.565]\n","Epoch 65:  67% 8/12 [00:02<00:01,  3.17it/s, loss=1.11, v_num=0, val_loss=1.520, val_acc_epoch=0.327, train_loss_step=1.060, train_loss_epoch=1.100, train_acc_epoch=0.565]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.52it/s]\u001b[A\n","Epoch 65:  83% 10/12 [00:02<00:00,  3.40it/s, loss=1.11, v_num=0, val_loss=1.520, val_acc_epoch=0.327, train_loss_step=1.060, train_loss_epoch=1.100, train_acc_epoch=0.565]\n","Validating:  60% 3/5 [00:00<00:00,  6.59it/s]\u001b[A\n","Epoch 65: 100% 12/12 [00:03<00:00,  3.63it/s, loss=1.11, v_num=0, val_loss=1.520, val_acc_epoch=0.333, train_loss_step=1.010, train_loss_epoch=1.150, train_acc_epoch=0.540]\n","Epoch 66:  67% 8/12 [00:02<00:01,  3.69it/s, loss=1.09, v_num=0, val_loss=1.520, val_acc_epoch=0.333, train_loss_step=1.070, train_loss_epoch=1.150, train_acc_epoch=0.540]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 66:  83% 10/12 [00:02<00:00,  4.11it/s, loss=1.09, v_num=0, val_loss=1.520, val_acc_epoch=0.333, train_loss_step=1.070, train_loss_epoch=1.150, train_acc_epoch=0.540]\n","Epoch 66: 100% 12/12 [00:02<00:00,  4.63it/s, loss=1.09, v_num=0, val_loss=1.520, val_acc_epoch=0.333, train_loss_step=1.070, train_loss_epoch=1.150, train_acc_epoch=0.540]\n","Epoch 66: 100% 12/12 [00:02<00:00,  4.43it/s, loss=1.09, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.050, train_loss_epoch=1.100, train_acc_epoch=0.535]\n","Epoch 67:  67% 8/12 [00:01<00:00,  4.27it/s, loss=1.13, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.160, train_loss_epoch=1.100, train_acc_epoch=0.535]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.76it/s]\u001b[A\n","Epoch 67:  83% 10/12 [00:02<00:00,  4.58it/s, loss=1.13, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.160, train_loss_epoch=1.100, train_acc_epoch=0.535]\n","Epoch 67: 100% 12/12 [00:02<00:00,  5.09it/s, loss=1.13, v_num=0, val_loss=1.530, val_acc_epoch=0.327, train_loss_step=1.160, train_loss_epoch=1.100, train_acc_epoch=0.535]Epoch 00068: reducing learning rate of group 0 to 2.5000e-05.\n","Epoch 67: 100% 12/12 [00:02<00:00,  4.84it/s, loss=1.13, v_num=0, val_loss=1.540, val_acc_epoch=0.327, train_loss_step=1.590, train_loss_epoch=1.120, train_acc_epoch=0.535]\n","Epoch 68:  67% 8/12 [00:01<00:00,  4.14it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.327, train_loss_step=0.902, train_loss_epoch=1.120, train_acc_epoch=0.535]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.95it/s]\u001b[A\n","Epoch 68:  83% 10/12 [00:02<00:00,  4.46it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.327, train_loss_step=0.902, train_loss_epoch=1.120, train_acc_epoch=0.535]\n","Epoch 68: 100% 12/12 [00:02<00:00,  4.67it/s, loss=1.11, v_num=0, val_loss=1.530, val_acc_epoch=0.333, train_loss_step=0.978, train_loss_epoch=1.070, train_acc_epoch=0.570]\n","Epoch 69:  67% 8/12 [00:01<00:00,  4.33it/s, loss=1.1, v_num=0, val_loss=1.530, val_acc_epoch=0.333, train_loss_step=1.090, train_loss_epoch=1.070, train_acc_epoch=0.570]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.66it/s]\u001b[A\n","Epoch 69:  83% 10/12 [00:02<00:00,  4.59it/s, loss=1.1, v_num=0, val_loss=1.530, val_acc_epoch=0.333, train_loss_step=1.090, train_loss_epoch=1.070, train_acc_epoch=0.570]\n","Epoch 69: 100% 12/12 [00:02<00:00,  4.86it/s, loss=1.1, v_num=0, val_loss=1.530, val_acc_epoch=0.320, train_loss_step=0.919, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Epoch 70:  67% 8/12 [00:01<00:00,  4.17it/s, loss=1.1, v_num=0, val_loss=1.530, val_acc_epoch=0.320, train_loss_step=1.060, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.11it/s]\u001b[A\n","Epoch 70:  83% 10/12 [00:02<00:00,  4.40it/s, loss=1.1, v_num=0, val_loss=1.530, val_acc_epoch=0.320, train_loss_step=1.060, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Validating:  60% 3/5 [00:00<00:00,  7.18it/s]\u001b[A\n","Epoch 70: 100% 12/12 [00:02<00:00,  4.54it/s, loss=1.1, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.310, train_loss_epoch=1.140, train_acc_epoch=0.530]\n","Epoch 71:  67% 8/12 [00:02<00:01,  3.19it/s, loss=1.11, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.130, train_loss_epoch=1.140, train_acc_epoch=0.530]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.31it/s]\u001b[A\n","Epoch 71:  83% 10/12 [00:02<00:00,  3.38it/s, loss=1.11, v_num=0, val_loss=1.530, val_acc_epoch=0.313, train_loss_step=1.130, train_loss_epoch=1.140, train_acc_epoch=0.530]\n","Validating:  60% 3/5 [00:00<00:00,  5.90it/s]\u001b[A\n","Epoch 71: 100% 12/12 [00:03<00:00,  3.58it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.858, train_loss_epoch=1.120, train_acc_epoch=0.535]\n","Epoch 72:  67% 8/12 [00:02<00:01,  3.87it/s, loss=1.12, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.030, train_loss_epoch=1.120, train_acc_epoch=0.535]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.89it/s]\u001b[A\n","Epoch 72:  83% 10/12 [00:02<00:00,  4.21it/s, loss=1.12, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.030, train_loss_epoch=1.120, train_acc_epoch=0.535]\n","Epoch 72: 100% 12/12 [00:02<00:00,  4.51it/s, loss=1.12, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.970, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 73:  67% 8/12 [00:01<00:00,  4.28it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.140, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.97it/s]\u001b[A\n","Epoch 73:  83% 10/12 [00:02<00:00,  4.59it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.140, train_loss_epoch=1.140, train_acc_epoch=0.520]\n","Epoch 73: 100% 12/12 [00:02<00:00,  4.94it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.661, train_loss_epoch=1.090, train_acc_epoch=0.540]\n","Epoch 74:  67% 8/12 [00:01<00:00,  5.00it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.160, train_loss_epoch=1.090, train_acc_epoch=0.540]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 74:  83% 10/12 [00:01<00:00,  5.36it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.160, train_loss_epoch=1.090, train_acc_epoch=0.540]\n","Epoch 74: 100% 12/12 [00:02<00:00,  5.95it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.160, train_loss_epoch=1.090, train_acc_epoch=0.540]\n","Epoch 74: 100% 12/12 [00:02<00:00,  5.66it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.110, train_loss_epoch=1.110, train_acc_epoch=0.540]\n","Epoch 75:  67% 8/12 [00:01<00:00,  5.02it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.160, train_loss_epoch=1.110, train_acc_epoch=0.540]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 75:  83% 10/12 [00:01<00:00,  5.38it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.160, train_loss_epoch=1.110, train_acc_epoch=0.540]\n","Epoch 75: 100% 12/12 [00:02<00:00,  5.97it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.160, train_loss_epoch=1.110, train_acc_epoch=0.540]\n","Epoch 75: 100% 12/12 [00:02<00:00,  5.70it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.882, train_loss_epoch=1.080, train_acc_epoch=0.560]\n","Epoch 76:  67% 8/12 [00:01<00:00,  5.23it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.080, train_loss_epoch=1.080, train_acc_epoch=0.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.40it/s]\u001b[A\n","Epoch 76:  83% 10/12 [00:01<00:00,  5.43it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.080, train_loss_epoch=1.080, train_acc_epoch=0.560]\n","Validating:  60% 3/5 [00:00<00:00,  7.78it/s]\u001b[A\n","Epoch 76: 100% 12/12 [00:02<00:00,  5.48it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.815, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Epoch 77:  67% 8/12 [00:02<00:01,  3.15it/s, loss=1.05, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.985, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  2.94it/s]\u001b[A\n","Epoch 77:  83% 10/12 [00:02<00:00,  3.34it/s, loss=1.05, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.985, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Validating:  60% 3/5 [00:00<00:00,  6.10it/s]\u001b[A\n","Epoch 77: 100% 12/12 [00:03<00:00,  3.58it/s, loss=1.05, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.985, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Epoch 78:  67% 8/12 [00:02<00:01,  3.18it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.060, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  2.92it/s]\u001b[A\n","Epoch 78:  83% 10/12 [00:02<00:00,  3.34it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.060, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Validating:  60% 3/5 [00:00<00:00,  5.49it/s]\u001b[A\n","Epoch 78: 100% 12/12 [00:03<00:00,  3.68it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.060, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Validating: 100% 5/5 [00:00<00:00,  7.04it/s]\u001b[AEpoch 00079: reducing learning rate of group 0 to 1.2500e-05.\n","Epoch 78: 100% 12/12 [00:03<00:00,  3.49it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.969, train_loss_epoch=1.080, train_acc_epoch=0.550]\n","Epoch 79:  67% 8/12 [00:02<00:01,  2.83it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.992, train_loss_epoch=1.080, train_acc_epoch=0.550]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  2.90it/s]\u001b[A\n","Epoch 79:  83% 10/12 [00:03<00:00,  3.00it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.992, train_loss_epoch=1.080, train_acc_epoch=0.550]\n","Validating:  60% 3/5 [00:00<00:00,  5.30it/s]\u001b[A\n","Epoch 79: 100% 12/12 [00:03<00:00,  3.34it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.992, train_loss_epoch=1.080, train_acc_epoch=0.550]\n","Epoch 79: 100% 12/12 [00:03<00:00,  3.16it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.883, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Epoch 80:  67% 8/12 [00:01<00:00,  4.72it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.905, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 80:  83% 10/12 [00:02<00:00,  4.94it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.905, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Epoch 80: 100% 12/12 [00:02<00:00,  5.49it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.905, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Epoch 80: 100% 12/12 [00:02<00:00,  5.19it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.140, train_loss_epoch=1.120, train_acc_epoch=0.575]\n","Epoch 81:  67% 8/12 [00:01<00:00,  4.74it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.250, train_loss_epoch=1.120, train_acc_epoch=0.575]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 81:  83% 10/12 [00:01<00:00,  5.07it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.250, train_loss_epoch=1.120, train_acc_epoch=0.575]\n","Epoch 81: 100% 12/12 [00:02<00:00,  5.58it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.250, train_loss_epoch=1.120, train_acc_epoch=0.575]\n","Epoch 81: 100% 12/12 [00:02<00:00,  5.29it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.250, train_loss_epoch=1.130, train_acc_epoch=0.520]\n","Epoch 82:  67% 8/12 [00:01<00:00,  4.46it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.060, train_loss_epoch=1.130, train_acc_epoch=0.520]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 82:  83% 10/12 [00:02<00:00,  4.84it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.060, train_loss_epoch=1.130, train_acc_epoch=0.520]\n","Epoch 82: 100% 12/12 [00:02<00:00,  5.42it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.060, train_loss_epoch=1.130, train_acc_epoch=0.520]\n","Epoch 82: 100% 12/12 [00:02<00:00,  5.15it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.080, train_loss_epoch=1.080, train_acc_epoch=0.565]\n","Epoch 83:  67% 8/12 [00:01<00:00,  5.01it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.190, train_loss_epoch=1.080, train_acc_epoch=0.565]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.66it/s]\u001b[A\n","Epoch 83:  83% 10/12 [00:01<00:00,  5.22it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.190, train_loss_epoch=1.080, train_acc_epoch=0.565]\n","Epoch 83: 100% 12/12 [00:02<00:00,  5.66it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.190, train_loss_epoch=1.080, train_acc_epoch=0.565]\n","Epoch 83: 100% 12/12 [00:02<00:00,  5.35it/s, loss=1.11, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.989, train_loss_epoch=1.090, train_acc_epoch=0.595]\n","Epoch 84:  67% 8/12 [00:02<00:01,  3.15it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.120, train_loss_epoch=1.090, train_acc_epoch=0.595]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.22it/s]\u001b[A\n","Epoch 84:  83% 10/12 [00:02<00:00,  3.46it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.120, train_loss_epoch=1.090, train_acc_epoch=0.595]\n","Validating:  60% 3/5 [00:00<00:00,  6.93it/s]\u001b[A\n","Epoch 84: 100% 12/12 [00:03<00:00,  3.69it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=0.888, train_loss_epoch=1.070, train_acc_epoch=0.550]\n","Epoch 85:  67% 8/12 [00:02<00:01,  3.28it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.090, train_loss_epoch=1.070, train_acc_epoch=0.550]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 85:  83% 10/12 [00:02<00:00,  3.58it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.090, train_loss_epoch=1.070, train_acc_epoch=0.550]\n","Epoch 85: 100% 12/12 [00:02<00:00,  4.02it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.090, train_loss_epoch=1.070, train_acc_epoch=0.550]\n","Epoch 85: 100% 12/12 [00:03<00:00,  3.88it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.170, train_loss_epoch=1.090, train_acc_epoch=0.570]\n","Epoch 86:  67% 8/12 [00:01<00:00,  4.34it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.050, train_loss_epoch=1.090, train_acc_epoch=0.570]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 86:  83% 10/12 [00:02<00:00,  4.68it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.050, train_loss_epoch=1.090, train_acc_epoch=0.570]\n","Epoch 86: 100% 12/12 [00:02<00:00,  5.23it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.050, train_loss_epoch=1.090, train_acc_epoch=0.570]\n","Epoch 86: 100% 12/12 [00:02<00:00,  5.02it/s, loss=1.07, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.030, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Epoch 87:  67% 8/12 [00:01<00:00,  4.36it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.030, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  5.01it/s]\u001b[A\n","Epoch 87:  83% 10/12 [00:02<00:00,  4.68it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.030, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Epoch 87: 100% 12/12 [00:02<00:00,  5.17it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.030, train_loss_epoch=1.080, train_acc_epoch=0.555]\n","Epoch 87: 100% 12/12 [00:02<00:00,  4.90it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.951, train_loss_epoch=1.090, train_acc_epoch=0.565]\n","Epoch 88:  67% 8/12 [00:01<00:00,  4.79it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.090, train_loss_epoch=1.090, train_acc_epoch=0.565]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 88:  83% 10/12 [00:01<00:00,  5.03it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.090, train_loss_epoch=1.090, train_acc_epoch=0.565]\n","Epoch 88: 100% 12/12 [00:02<00:00,  5.49it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.090, train_loss_epoch=1.090, train_acc_epoch=0.565]\n","Epoch 88: 100% 12/12 [00:02<00:00,  5.20it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.000, train_loss_epoch=1.100, train_acc_epoch=0.585]\n","Epoch 89:  67% 8/12 [00:01<00:00,  4.19it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.080, train_loss_epoch=1.100, train_acc_epoch=0.585]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.57it/s]\u001b[A\n","Epoch 89:  83% 10/12 [00:02<00:00,  4.48it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.080, train_loss_epoch=1.100, train_acc_epoch=0.585]\n","Epoch 89: 100% 12/12 [00:02<00:00,  4.96it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.080, train_loss_epoch=1.100, train_acc_epoch=0.585]\n","Validating: 100% 5/5 [00:00<00:00,  8.82it/s]\u001b[AEpoch 00090: reducing learning rate of group 0 to 6.2500e-06.\n","Epoch 89: 100% 12/12 [00:02<00:00,  4.62it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.100, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Epoch 90:  67% 8/12 [00:02<00:01,  3.08it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.100, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.08it/s]\u001b[A\n","Epoch 90:  83% 10/12 [00:03<00:00,  3.26it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.100, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Validating:  60% 3/5 [00:00<00:00,  5.55it/s]\u001b[A\n","Epoch 90: 100% 12/12 [00:03<00:00,  3.60it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.100, train_loss_epoch=1.080, train_acc_epoch=0.575]\n","Epoch 90: 100% 12/12 [00:03<00:00,  3.40it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.170, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Epoch 91:  67% 8/12 [00:02<00:01,  3.19it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.040, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.95it/s]\u001b[A\n","Epoch 91:  83% 10/12 [00:02<00:00,  3.54it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.307, train_loss_step=1.040, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Epoch 91: 100% 12/12 [00:03<00:00,  3.88it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.010, train_loss_epoch=1.070, train_acc_epoch=0.565]\n","Epoch 92:  67% 8/12 [00:01<00:00,  4.62it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.070, train_loss_epoch=1.070, train_acc_epoch=0.565]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 92:  83% 10/12 [00:02<00:00,  4.93it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.070, train_loss_epoch=1.070, train_acc_epoch=0.565]\n","Epoch 92: 100% 12/12 [00:02<00:00,  5.48it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.070, train_loss_epoch=1.070, train_acc_epoch=0.565]\n","Epoch 92: 100% 12/12 [00:02<00:00,  5.25it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.969, train_loss_epoch=1.130, train_acc_epoch=0.500]\n","Epoch 93:  67% 8/12 [00:01<00:00,  5.20it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.090, train_loss_epoch=1.130, train_acc_epoch=0.500]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  6.10it/s]\u001b[A\n","Epoch 93:  83% 10/12 [00:01<00:00,  5.52it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.090, train_loss_epoch=1.130, train_acc_epoch=0.500]\n","Epoch 93: 100% 12/12 [00:02<00:00,  5.62it/s, loss=1.09, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.946, train_loss_epoch=1.080, train_acc_epoch=0.560]\n","Epoch 94:  67% 8/12 [00:01<00:00,  4.78it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.938, train_loss_epoch=1.080, train_acc_epoch=0.560]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.44it/s]\u001b[A\n","Epoch 94:  83% 10/12 [00:02<00:00,  4.97it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.938, train_loss_epoch=1.080, train_acc_epoch=0.560]\n","Epoch 94: 100% 12/12 [00:02<00:00,  5.16it/s, loss=1.08, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=1.130, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Epoch 95:  67% 8/12 [00:01<00:00,  4.17it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.942, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.89it/s]\u001b[A\n","Epoch 95:  83% 10/12 [00:02<00:00,  4.49it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.942, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Validating:  60% 3/5 [00:00<00:00,  7.45it/s]\u001b[A\n","Epoch 95: 100% 12/12 [00:02<00:00,  4.86it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.942, train_loss_epoch=1.060, train_acc_epoch=0.585]\n","Epoch 95: 100% 12/12 [00:02<00:00,  4.60it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.956, train_loss_epoch=1.030, train_acc_epoch=0.625]\n","Epoch 96:  67% 8/12 [00:02<00:01,  3.25it/s, loss=1.03, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.902, train_loss_epoch=1.030, train_acc_epoch=0.625]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:01,  3.50it/s]\u001b[A\n","Epoch 96:  83% 10/12 [00:02<00:00,  3.47it/s, loss=1.03, v_num=0, val_loss=1.540, val_acc_epoch=0.313, train_loss_step=0.902, train_loss_epoch=1.030, train_acc_epoch=0.625]\n","Validating:  60% 3/5 [00:00<00:00,  6.44it/s]\u001b[A\n","Epoch 96: 100% 12/12 [00:03<00:00,  3.67it/s, loss=1.03, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.140, train_loss_epoch=1.030, train_acc_epoch=0.610]\n","Epoch 97:  67% 8/12 [00:02<00:01,  3.38it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.050, train_loss_epoch=1.030, train_acc_epoch=0.610]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.88it/s]\u001b[A\n","Epoch 97:  83% 10/12 [00:02<00:00,  3.73it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.050, train_loss_epoch=1.030, train_acc_epoch=0.610]\n","Epoch 97: 100% 12/12 [00:03<00:00,  3.99it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.230, train_loss_epoch=1.070, train_acc_epoch=0.610]\n","Epoch 98:  67% 8/12 [00:01<00:00,  4.84it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.060, train_loss_epoch=1.070, train_acc_epoch=0.610]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Validating:  20% 1/5 [00:00<00:00,  4.86it/s]\u001b[A\n","Epoch 98:  83% 10/12 [00:01<00:00,  5.08it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=1.060, train_loss_epoch=1.070, train_acc_epoch=0.610]\n","Epoch 98: 100% 12/12 [00:02<00:00,  5.29it/s, loss=1.06, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.858, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Epoch 99:  67% 8/12 [00:01<00:00,  4.88it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.923, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Validating: 0it [00:00, ?it/s]\u001b[A\n","Validating:   0% 0/5 [00:00<?, ?it/s]\u001b[A\n","Epoch 99:  83% 10/12 [00:01<00:00,  5.27it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.923, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Epoch 99: 100% 12/12 [00:02<00:00,  5.84it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.923, train_loss_epoch=1.040, train_acc_epoch=0.610]\n","Epoch 99: 100% 12/12 [00:02<00:00,  5.56it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.796, train_loss_epoch=1.050, train_acc_epoch=0.620]\n","Epoch 99: 100% 12/12 [00:02<00:00,  5.55it/s, loss=1.04, v_num=0, val_loss=1.540, val_acc_epoch=0.320, train_loss_step=0.796, train_loss_epoch=1.050, train_acc_epoch=0.620]\n","Testing: 100% 7/7 [00:00<00:00, 11.12it/s]\n","--------------------------------------------------------------------------------\n","DATALOADER:0 TEST RESULTS\n","{'test_acc_best_epoch': 0.42500001192092896, 'test_loss': 1.3911406993865967}\n","--------------------------------------------------------------------------------\n","Path to best model found during training: \n","/content/outputs/2023-06-11/20-35-11/lightning_logs/version_0/checkpoints/56-398.ckpt\n"]}]},{"cell_type":"markdown","source":["## Supervised learning only"],"metadata":{"id":"NyPOPTmDOePz"}},{"cell_type":"code","source":["# bare SUP\n","\n","!python /content/saint/main.py experiment=supervised \\\n","  experiment.model=saint \\\n","  data.data_folder=/content/saint/data \\\n","  data=bank_sup"],"metadata":{"id":"dEoRCf56GlGD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686513770596,"user_tz":-420,"elapsed":2508,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"0e6d4763-99ab-4da9-e88d-25b9f4f15ece"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/content/saint/main.py\", line 4, in <module>\n","    from pytorch_lightning import seed_everything\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py\", line 20, in <module>\n","    from pytorch_lightning import metrics  # noqa: E402\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/__init__.py\", line 15, in <module>\n","    from pytorch_lightning.metrics.classification import (  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.classification.accuracy import Accuracy  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/accuracy.py\", line 16, in <module>\n","    from torchmetrics import Accuracy as _Accuracy\n","  File \"/usr/local/lib/python3.10/dist-packages/torchmetrics/__init__.py\", line 14, in <module>\n","    from torchmetrics.average import AverageMeter  # noqa: F401 E402\n","  File \"/usr/local/lib/python3.10/dist-packages/torchmetrics/average.py\", line 16, in <module>\n","    import torch\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1465, in <module>\n","    from . import _meta_registrations\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 7, in <module>\n","    from torch._decomp import _add_op_to_registry, global_decomposition_table, meta_table\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/__init__.py\", line 169, in <module>\n","    import torch._decomp.decompositions\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\", line 10, in <module>\n","    import torch._prims as prims\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_prims/__init__.py\", line 33, in <module>\n","    from torch._subclasses.fake_tensor import FakeTensor, FakeTensorMode\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/__init__.py\", line 3, in <module>\n","    from torch._subclasses.fake_tensor import (\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 13, in <module>\n","    from torch._guards import Source\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_guards.py\", line 14, in <module>\n","    import sympy  # type: ignore[import]\n","  File \"/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\", line 196, in <module>\n","    from .geometry import (Point, Point2D, Point3D, Line, Ray, Segment, Line2D,\n","  File \"/usr/local/lib/python3.10/dist-packages/sympy/geometry/__init__.py\", line 22, in <module>\n","    from sympy.geometry.curve import Curve\n","  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 1002, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 937, in _find_spec\n","  File \"<frozen importlib._bootstrap>\", line 893, in __enter__\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"gvrjFwH2JpA-"}},{"cell_type":"code","source":["pretrained_checkpoint = \"/content/outputs/2023-06-11/20-03-11/lightning_logs/version_0/checkpoints/56-398.ckpt\""],"metadata":{"id":"pbNGb90_qzMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/saint/predict.py experiment=predict \\\n","  experiment.model=saint \\\n","  data=bank_sup \\\n","  data.data_folder=/content/saint/data \\\n","  experiment.pretrained_checkpoint={pretrained_checkpoint} \\\n","  experiment.pred_sav_path=/content/predict.csv"],"metadata":{"id":"2BkcD_bOHJlX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686514897120,"user_tz":-420,"elapsed":10723,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"82f1be31-e3c8-4d4d-93ae-063477d8e21e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-11 20:21:32.260458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-06-11 20:21:33.540769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","/content/saint/predict.py:15: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"configs\", config_name=\"config\")\n","/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","{'seed': 1234, 'transformer': {'num_layers': 6, 'num_heads': 8, 'dropout': 0.1, 'dropout_ff': 0.1, 'embed_dim': 32, 'd_ff': 32, 'cls_token_idx': 0}, 'augmentation': {'prob_cutmix': 0.3, 'alpha': 0.2, 'lambda_pt': 10}, 'optimizer': {'temperature': 0.7, 'proj_head_dim': 128, 'beta_1': 0.9, 'beta_2': 0.99, 'lr': 0.0001, 'weight_decay': 0.01, 'optim': 'adamw', 'metric': 'auroc'}, 'preproc': {'data_folder': None, 'train_split': 0.65, 'validation_split': 0.15, 'test_split': 0.2, 'num_supervised_train_data': None}, 'callback': {'monitor': 'val_loss', 'mode': 'min', 'auto_insert_metric_name': False}, 'trainer': {'max_epochs': 100, 'deterministic': True, 'default_root_dir': None}, 'dataloader': {'shuffle_val': False, 'train_bs': 32, 'val_bs': 32, 'test_bs': 16, 'num_workers': 2, 'pin_memory': False}, 'metric': '${optimizer.metric}', 'print_config': False, 'experiment': {'model': 'saint', 'task': 'classification', 'pretrained_checkpoint': '/content/outputs/2023-06-11/20-03-11/lightning_logs/version_0/checkpoints/56-398.ckpt', 'num_output': 1, 'pred_sav_path': '/content/predict.csv', 'save_prediction': True, 'id_col': 'index', 'target_col': 'target'}, 'data': {'data_folder': '/content/saint/data', 'data_paths': {'train_csv_path': '${data.data_folder}/train.csv', 'train_y_csv_path': '${data.data_folder}/train_y.csv', 'val_csv_path': '${data.data_folder}/val.csv', 'val_y_csv_path': '${data.data_folder}/val_y.csv', 'test_csv_path': '${data.data_folder}/test.csv', 'test_y_csv_path': '${data.data_folder}/test_y.csv'}, 'data_stats': {'no_cat': 1, 'no_num': 49, 'cats': [1]}}}\n","/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n","  warnings.warn(*args, **kwargs)\n","Prediction finished,  csv saved at /content/predict.csv\n"]}]},{"cell_type":"code","source":["pred = pd.read_csv(\"/content/predict.csv\")\n","pred['target'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkms-sdgJFYA","executionInfo":{"status":"ok","timestamp":1686515329523,"user_tz":-420,"elapsed":1064,"user":{"displayName":"Mar Ammar","userId":"11100875506678644540"}},"outputId":"e5726bc0-423d-45da-d0f0-3dd93a68dac3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    160\n","1     40\n","Name: target, dtype: int64"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":[],"metadata":{"id":"V9pdLifpJ0ug"},"execution_count":null,"outputs":[]}]}